{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from boxmot import BotSort\n",
    "from torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-10-25 20:38:58.166\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mboxmot.utils.torch_utils\u001b[0m:\u001b[36mselect_device\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mYolo Tracking v11.0.2 ðŸš€ Python-3.10.6 torch-2.2.1+cu118\n",
      "CUDA:0 (NVIDIA GeForce RTX 4070 SUPER, 12282MiB)\u001b[0m\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1sSwXSUlj4_tHZequ_iZ8w_Jh0VaRQMqF\n",
      "To: d:\\project\\prjvenv\\osnet_x0_25_msmt17.pt\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.06M/3.06M [00:00<00:00, 10.6MB/s]\n",
      "\u001b[32m2024-10-25 20:39:02.478\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36mboxmot.appearance.reid_model_factory\u001b[0m:\u001b[36mload_pretrained_weights\u001b[0m:\u001b[36m183\u001b[0m - \u001b[32m\u001b[1mLoaded pretrained weights from osnet_x0_25_msmt17.pt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "detector = torchvision.models.detection.fasterrcnn_resnet50_fpn(weights = FasterRCNN_ResNet50_FPN_Weights.COCO_V1)\n",
    "detector.eval().to(device)\n",
    "\n",
    "# Initialize the tracker\n",
    "tracker = BotSort(\n",
    "    reid_weights=Path('osnet_x0_25_msmt17.pt'),  # Path to ReID model\n",
    "    device=device, \n",
    "    half=False\n",
    ")\n",
    "\n",
    "vid = cv2.VideoCapture(r'D:\\041.ë‚™ìƒì‚¬ê³  ìœ„í—˜ë™ìž‘ ì˜ìƒ-ì„¼ì„œ ìŒ ë°ì´í„°\\3.ê°œë°©ë°ì´í„°\\1.ë°ì´í„°\\Training\\01.ì›ì²œë°ì´í„°\\TS\\ì˜ìƒ\\Y\\BY\\00050_H_A_BY_C1\\00050_H_A_BY_C1.mp4') \n",
    "if not vid.isOpened() :\n",
    "    print('ëª»ì—´ì—ˆìŒ')\n",
    "    exit()\n",
    "\n",
    "fps = vid.get(cv2.CAP_PROP_FPS)\n",
    "frame_w = int(vid.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_h = int(vid.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "total_frame = fps * 10\n",
    "\n",
    "result_path = 'ehlfRK.mp4' \n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter(result_path, fourcc, 25, (frame_w, frame_h))\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = vid.read()\n",
    "    if not ret or frame_count >= total_frame : \n",
    "        break\n",
    "    # If ret is False, it means we have reached the end of the video\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Convert frame to tensor and move to device\n",
    "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_tensor = torchvision.transforms.functional.to_tensor(frame).to(device)\n",
    "\n",
    "    # Perform detection\n",
    "    with torch.no_grad():\n",
    "        detections = detector([frame_tensor])[0]\n",
    "\n",
    "    # Filter the detections (e.g., based on confidence threshold)\n",
    "    confidence_threshold = 0.5\n",
    "    dets = []\n",
    "    for i, score in enumerate(detections['scores']):\n",
    "        if score >= confidence_threshold:\n",
    "            bbox = detections['boxes'][i].cpu().numpy()\n",
    "            label = detections['labels'][i].item()\n",
    "            conf = score.item()\n",
    "            dets.append([*bbox, conf, label])\n",
    "\n",
    "    # Convert detections to numpy array (N X (x, y, x, y, conf, cls))\n",
    "    dets = np.array(dets)\n",
    "\n",
    "    # Update the tracker\n",
    "    res = tracker.update(dets, frame)  # --> M X (x, y, x, y, id, conf, cls, ind)\n",
    "\n",
    "    # Plot tracking results on the image\n",
    "    tracker.plot_results(frame, show_trajectories=True)\n",
    "    out.write(frame)\n",
    "    \n",
    "    cv2.imshow('BoXMOT + Torchvision', frame)\n",
    "    \n",
    "    frame_count += 1\n",
    "    # Simulate wait for key press to continue, press 'q' to exit\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "vid.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

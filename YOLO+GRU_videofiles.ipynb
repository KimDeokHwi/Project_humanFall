{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from scipy.spatial import distance\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### yolo, GRU 동시 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 Fall, 6.0ms\n",
      "Speed: 3.0ms preprocess, 6.0ms inference, 71.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Transformed coordinates: (2124.3585205078125, 799.4786682128906, 2524.6387939453125, 1467.958969116211)\n",
      "Input data length: 27, expected length: 27\n",
      "Predicted Class: 2, Probabilities: [   0.027933     0.17902     0.79305]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'bbox_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 168\u001b[0m\n\u001b[0;32m    165\u001b[0m prev_landmarks\u001b[38;5;241m=\u001b[39mlandmarks \n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# 바운딩 박스와 라벨 그리기 \u001b[39;00m\n\u001b[1;32m--> 168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[43mbbox_info\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(bbox_info) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    169\u001b[0m     x1 , y1 , x2 , y2\u001b[38;5;241m=\u001b[39mbbox_info[\u001b[38;5;241m0\u001b[39m]   \n\u001b[0;32m    170\u001b[0m     color\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m ,\u001b[38;5;241m255\u001b[39m ,\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m label\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m ((\u001b[38;5;241m255\u001b[39m ,\u001b[38;5;241m255\u001b[39m ,\u001b[38;5;241m0\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m label\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;241m255\u001b[39m ,\u001b[38;5;241m0\u001b[39m ,\u001b[38;5;241m0\u001b[39m)) \n",
      "\u001b[1;31mNameError\u001b[0m: name 'bbox_info' is not defined"
     ]
    }
   ],
   "source": [
    "# 랜드마크 인덱스 정의 (예: 코, 왼쪽 어깨, 오른쪽 어깨 등)\n",
    "LANDMARKS = [0, 11, 12, 15, 16, 23, 24, 25, 26, 27, 28]  # 총 11개 랜드마크\n",
    "\n",
    "# YOLO 모델 로드\n",
    "yolo_model = YOLO('D:\\\\project\\\\prjvenv\\\\runs\\\\detect\\\\human_fall_s30\\\\weights\\\\best.pt')\n",
    "\n",
    "# GRU 모델 정의 및 로드 \n",
    "class GRUModel(torch.nn.Module):\n",
    "    def __init__(self, input_size=27):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size = 64\n",
    "        self.num_layers = num_layers = 2\n",
    "        self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True,\n",
    "                          dropout=0.5)\n",
    "        self.fc = nn.Linear(hidden_size, 3)  # output_size를 직접 지정합니다.\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# GRU 모델 로드\n",
    "input_size = len(LANDMARKS) * 2 + 5   # 랜드마크 (22) + 바운딩박스 정보 (4) + 속도 (1) + 클래스 (1) \n",
    "gru_model = GRUModel(input_size=input_size)  \n",
    "gru_model.load_state_dict(torch.load('D:\\\\project\\\\prjvenv\\\\GRU\\\\best_GRU_model_2.pt', map_location=torch.device('cpu')))\n",
    "gru_model.eval()\n",
    "\n",
    "# 클래스 이름 정의\n",
    "class_names = {0: 'Normal', 1: 'Fall', 2: 'Danger'}\n",
    "\n",
    "def calculate_head_upper_body_speed(keypoints, prev_keypoints):\n",
    "    h = np.array([keypoints[0, 0], keypoints[0, 1]])   # 머리 좌표\n",
    "    l = np.array([keypoints[11, 0], keypoints[11, 1]])  # 왼쪽 어깨 좌표\n",
    "    r = np.array([keypoints[12, 0], keypoints[12, 1]])  # 오른쪽 어깨 좌표\n",
    "\n",
    "    # 이전 프레임의 좌표\n",
    "    prev_h = np.array([prev_keypoints[0, 0], prev_keypoints[0, 1]])\n",
    "    prev_l = np.array([prev_keypoints[11, 0], prev_keypoints[11, 1]])\n",
    "    prev_r = np.array([prev_keypoints[12, 0], prev_keypoints[12, 1]])\n",
    "\n",
    "    # 현재 프레임과 이전 프레임의 상체 중심 계산\n",
    "    center_new = (h + l + r) / 3\n",
    "    center_prev = (prev_h + prev_l + prev_r) / 3\n",
    "\n",
    "    # 유클리드 거리 계산 (속도)\n",
    "    speed = distance.euclidean(center_new, center_prev)\n",
    "    return speed\n",
    "\n",
    "def process_landmarks(landmarks): \n",
    "    selected_landmarks = landmarks[LANDMARKS]   # 지정된 랜드마크 선택 \n",
    "    return selected_landmarks[:, :2].flatten()   # (x,y) 좌표 반환\n",
    "\n",
    "def detect_fall(landmarks, prev_landmarks):\n",
    "    speed = calculate_head_upper_body_speed(landmarks, prev_landmarks) if prev_landmarks is not None else 0\n",
    "    processed_landmarks = process_landmarks(landmarks)\n",
    "\n",
    "    # 비디오 프레임을 YOLO 입력 크기로 리사이즈\n",
    "    resized_frame = cv2.resize(frame, (640, 640))\n",
    "    \n",
    "    # YOLO를 사용하여 바운딩 박스 예측\n",
    "    results = yolo_model(resized_frame)\n",
    "   \n",
    "    # YOLO 예측 결과에서 바운딩 박스 정보 가져오기 \n",
    "    bbox_info=results[0].boxes.xyxy.cpu().numpy() if results and len(results[0].boxes) > 0 else None\n",
    "    \n",
    "    if bbox_info is None or len(bbox_info) == 0:\n",
    "       print(\"No bounding boxes detected.\")\n",
    "       return None , None\n",
    "\n",
    "    # 첫 번째 바운딩 박스 정보 가져오기 (여러 개가 있을 경우 첫 번째만 사용)\n",
    "    x1 , y1 , x2 , y2=bbox_info[0]  \n",
    "    \n",
    "    # 바운딩 박스 좌표를 원본 프레임에 맞게 변환 (640x640에서 원본 크기로)\n",
    "    original_width = frame.shape[1]\n",
    "    original_height = frame.shape[0]\n",
    "    x1, y1, x2, y2 = bbox_info[0]\n",
    "    \n",
    "    x1 *= original_width / 640.0\n",
    "    x2 *= original_width / 640.0\n",
    "    y1 *= original_height / 640.0\n",
    "    y2 *= original_height / 640.0\n",
    "    print(f\"Transformed coordinates: {(x1, y1, x2, y2)}\")\n",
    "\n",
    "    bbox_width=x2 - x1 \n",
    "    bbox_height=y2 - y1  \n",
    "   \n",
    "    bbox_ratio=bbox_width / bbox_height if bbox_height !=0 else float('inf')\n",
    "   \n",
    "    # 클래스 결정 \n",
    "    if bbox_ratio <=1.3:\n",
    "       bbox_class=0   # Normal \n",
    "    elif bbox_ratio <=1.7:\n",
    "       bbox_class=2   # Danger \n",
    "    else:\n",
    "       bbox_class=1   # Fall \n",
    "\n",
    "    # 입력 데이터 구성 \n",
    "    input_data=np.concatenate([processed_landmarks,\n",
    "                               [bbox_width,\n",
    "                                bbox_height,\n",
    "                                bbox_ratio,\n",
    "                                speed,\n",
    "                                bbox_class]])\n",
    "\n",
    "    print(f\"Input data length: {len(input_data)}, expected length: {input_size}\")\n",
    "\n",
    "    if len(input_data) != input_size:\n",
    "       print(f\"Warning: input_data length is {len(input_data)}, expected {input_size}\")\n",
    "       return None , None\n",
    "    \n",
    "    input_tensor=torch.FloatTensor(input_data).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "       output=gru_model(input_tensor)\n",
    "\n",
    "    probabilities=torch.softmax(output , dim=1).cpu().numpy()[0]  \n",
    "    predicted_class=torch.argmax(output).item()\n",
    "    \n",
    "    return predicted_class , probabilities\n",
    "\n",
    "# 비디오 파일 경로 지정 및 열기 \n",
    "video_path=\"D:\\\\human_fall\\\\re_video\\\\training\\\\Y\\\\01452_O_B_FY_C8.mp4\"\n",
    "cap=cv2.VideoCapture(video_path)\n",
    "\n",
    "# 비디오 속성 가져오기 \n",
    "width=int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height=int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps=cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# 출력 비디오 설정 \n",
    "fourcc=cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out_path='data_video_test_outputY_GRU_yolo.mp4'\n",
    "out=cv2.VideoWriter(out_path,fourcc,fps,(width,height))\n",
    "\n",
    "prev_landmarks=None\n",
    "\n",
    "# 프레임 처리 루프 \n",
    "while cap.isOpened():\n",
    "    ret , frame=cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "       break\n",
    "\n",
    "    rgb_frame=cv2.cvtColor(frame , cv2.COLOR_BGR2RGB)\n",
    "    results_pose=pose.process(rgb_frame)\n",
    "\n",
    "    if results_pose.pose_landmarks:\n",
    "        \n",
    "        landmarks=np.array([[lm.x * width , lm.y * height , lm.z] for lm in results_pose.pose_landmarks.landmark])\n",
    "       \n",
    "        if prev_landmarks is not None: \n",
    "            result=detect_fall(landmarks , prev_landmarks)\n",
    "            if result is not None:  \n",
    "                label , probs=result \n",
    "                print(f\"Predicted Class: {label}, Probabilities: {probs}\")  \n",
    "            else:\n",
    "                print(\"Detection failed.\")\n",
    "        else: \n",
    "            label=None \n",
    "\n",
    "        prev_landmarks=landmarks \n",
    "\n",
    "        # 바운딩 박스와 라벨 그리기 \n",
    "        if label is not None and bbox_info is not None and len(bbox_info) > 0:\n",
    "            x1 , y1 , x2 , y2=bbox_info[0]   \n",
    "            color=(0 ,255 ,0) if label==0 else ((255 ,255 ,0) if label==2 else (255 ,0 ,0)) \n",
    "            cv2.rectangle(frame , (int(x1), int(y1)), (int(x2), int(y2)), color ,2)\n",
    "            class_name=class_names[label] if label is not None else 'Unknown'\n",
    "            cv2.putText(frame , f'GRU: {class_name}' , (int(x1) , int(y1) -10) , cv2.FONT_HERSHEY_SIMPLEX ,0.7 , color ,2)\n",
    "            print(\"YOLO results:\", results[0].boxes.xyxy.cpu().numpy())\n",
    "            print(\"Classes:\", results[0].boxes.cls.cpu().numpy())\n",
    "            print(\"Confidences:\", results[0].boxes.conf.cpu().numpy())\n",
    "        # 랜드마크 표시 \n",
    "        mp_drawing.draw_landmarks(frame , results_pose.pose_landmarks , mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    # 프레임 저장 및 출력 \n",
    "    resized_frame=cv2.resize(frame,(1920, 1080))\n",
    "    out.write(resized_frame) \n",
    "    cv2.imshow('Fall Detection', resized_frame) \n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU 모델만 사용\n",
    "* bbox의 비율을 기준으로 클래스 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed landmarks length: 22\n",
      "BBox width: 439, height: 358, ratio: 1.2262569832402235, speed: 22.330371340889418\n",
      "Predicted Class: 1, Probabilities: [   0.038052     0.73953     0.22242]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 441, height: 394, ratio: 1.119289340101523, speed: 7.060977690259665\n",
      "Predicted Class: 1, Probabilities: [   0.037483     0.74019     0.22233]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 484, height: 417, ratio: 1.160671462829736, speed: 56.794296189125006\n",
      "Predicted Class: 1, Probabilities: [   0.023751     0.77615      0.2001]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 389, height: 371, ratio: 1.0485175202156334, speed: 38.520641438712275\n",
      "Predicted Class: 1, Probabilities: [   0.038052     0.73953     0.22242]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 486, height: 395, ratio: 1.230379746835443, speed: 18.204313168576896\n",
      "Predicted Class: 1, Probabilities: [   0.023676     0.75962     0.21671]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 567, height: 413, ratio: 1.3728813559322033, speed: 1.180409266889902\n",
      "Predicted Class: 1, Probabilities: [   0.020216     0.64278     0.33701]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 463, height: 378, ratio: 1.2248677248677249, speed: 10.389215105249704\n",
      "Predicted Class: 1, Probabilities: [   0.038052     0.73953     0.22242]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 452, height: 372, ratio: 1.2150537634408602, speed: 8.359958287053491\n",
      "Predicted Class: 1, Probabilities: [   0.038052     0.73953     0.22242]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 493, height: 409, ratio: 1.2053789731051345, speed: 24.363257791504278\n",
      "Predicted Class: 1, Probabilities: [   0.023677      0.7596     0.21673]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 449, height: 399, ratio: 1.1253132832080202, speed: 14.875019644454314\n",
      "Predicted Class: 1, Probabilities: [   0.039214     0.71736     0.24343]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 511, height: 394, ratio: 1.2969543147208122, speed: 34.77831455170744\n",
      "Predicted Class: 1, Probabilities: [   0.024224     0.75558      0.2202]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 490, height: 419, ratio: 1.1694510739856803, speed: 58.294960707338376\n",
      "Predicted Class: 1, Probabilities: [   0.023738     0.77635     0.19991]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 535, height: 415, ratio: 1.2891566265060241, speed: 12.640811025272486\n",
      "Predicted Class: 1, Probabilities: [    0.02982     0.62217     0.34801]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 516, height: 393, ratio: 1.3129770992366412, speed: 64.7742236956106\n",
      "Predicted Class: 1, Probabilities: [   0.023738     0.77635     0.19991]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 508, height: 394, ratio: 1.2893401015228427, speed: 17.720338583889024\n",
      "Predicted Class: 1, Probabilities: [   0.023672     0.75959     0.21673]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 527, height: 360, ratio: 1.4638888888888888, speed: 42.48163618554981\n",
      "Predicted Class: 1, Probabilities: [     0.0268     0.72271     0.25049]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 535, height: 394, ratio: 1.3578680203045685, speed: 36.9267393658044\n",
      "Predicted Class: 1, Probabilities: [    0.02982     0.62217     0.34801]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 521, height: 395, ratio: 1.3189873417721518, speed: 26.376961503667555\n",
      "Predicted Class: 1, Probabilities: [   0.023057     0.53439     0.44255]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 522, height: 414, ratio: 1.2608695652173914, speed: 9.033309364449549\n",
      "Predicted Class: 1, Probabilities: [    0.02716     0.57326     0.39958]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 452, height: 417, ratio: 1.0839328537170263, speed: 6.659568440014946\n",
      "Predicted Class: 1, Probabilities: [   0.043174     0.54507     0.41175]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 473, height: 417, ratio: 1.1342925659472423, speed: 4.124104965384208\n",
      "Predicted Class: 1, Probabilities: [   0.027854     0.57921     0.39294]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 465, height: 445, ratio: 1.0449438202247192, speed: 23.47279252414662\n",
      "Predicted Class: 1, Probabilities: [   0.029126     0.57416     0.39672]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 518, height: 429, ratio: 1.2074592074592074, speed: 10.27668642597605\n",
      "Predicted Class: 1, Probabilities: [   0.027854     0.57921     0.39294]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 474, height: 420, ratio: 1.1285714285714286, speed: 5.7479763688386685\n",
      "Predicted Class: 1, Probabilities: [   0.027984     0.58306     0.38895]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 493, height: 419, ratio: 1.1766109785202863, speed: 13.293246787166458\n",
      "Predicted Class: 1, Probabilities: [   0.027854     0.57921     0.39294]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 476, height: 398, ratio: 1.1959798994974875, speed: 10.43288997365509\n",
      "Predicted Class: 1, Probabilities: [   0.027904     0.57898     0.39311]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 452, height: 393, ratio: 1.1501272264631044, speed: 8.593890508484314\n",
      "Predicted Class: 1, Probabilities: [   0.043678     0.59266     0.36366]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 470, height: 393, ratio: 1.1959287531806615, speed: 16.92230142169413\n",
      "Predicted Class: 1, Probabilities: [   0.029819     0.62218       0.348]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 517, height: 395, ratio: 1.308860759493671, speed: 11.587544456619359\n",
      "Predicted Class: 1, Probabilities: [   0.023131     0.53516     0.44171]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 448, height: 395, ratio: 1.1341772151898735, speed: 5.581405822061484\n",
      "Predicted Class: 1, Probabilities: [   0.043671     0.59223      0.3641]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 511, height: 390, ratio: 1.3102564102564103, speed: 9.315064964157136\n",
      "Predicted Class: 1, Probabilities: [    0.02982     0.62217     0.34801]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 507, height: 390, ratio: 1.3, speed: 12.15797191266686\n",
      "Predicted Class: 1, Probabilities: [    0.02982     0.62217     0.34801]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 500, height: 388, ratio: 1.288659793814433, speed: 3.6759463047574803\n",
      "Predicted Class: 1, Probabilities: [   0.029818     0.62224     0.34794]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 507, height: 380, ratio: 1.3342105263157895, speed: 4.76168224703661\n",
      "Predicted Class: 1, Probabilities: [   0.026816     0.72238     0.25081]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 458, height: 375, ratio: 1.2213333333333334, speed: 2.495326162326622\n",
      "Predicted Class: 1, Probabilities: [   0.026816      0.7224     0.25079]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 474, height: 375, ratio: 1.264, speed: 14.102319883904734\n",
      "Predicted Class: 1, Probabilities: [   0.042324      0.6842     0.27347]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 462, height: 404, ratio: 1.1435643564356435, speed: 3.9924133847473535\n",
      "Predicted Class: 1, Probabilities: [   0.026788       0.723     0.25022]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 436, height: 367, ratio: 1.1880108991825613, speed: 5.522345393769899\n",
      "Predicted Class: 1, Probabilities: [   0.038052     0.73953     0.22242]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 457, height: 403, ratio: 1.1339950372208436, speed: 3.877708361272809\n",
      "Predicted Class: 1, Probabilities: [   0.025068     0.75947     0.21546]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 476, height: 433, ratio: 1.0993071593533488, speed: 3.7727309751048397\n",
      "Predicted Class: 1, Probabilities: [   0.027127     0.70987     0.26301]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 430, height: 412, ratio: 1.0436893203883495, speed: 29.47519218634103\n",
      "Predicted Class: 1, Probabilities: [   0.042011     0.69957     0.25841]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 393, height: 377, ratio: 1.0424403183023874, speed: 16.670984340899302\n",
      "Predicted Class: 1, Probabilities: [   0.038052     0.73953     0.22242]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 414, height: 377, ratio: 1.0981432360742707, speed: 0.6755347085449986\n",
      "Predicted Class: 1, Probabilities: [   0.038052     0.73953     0.22242]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 508, height: 407, ratio: 1.2481572481572483, speed: 51.696142800794824\n",
      "Predicted Class: 2, Probabilities: [   0.046515     0.46512     0.48837]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 479, height: 344, ratio: 1.3924418604651163, speed: 53.84530779338041\n",
      "Predicted Class: 1, Probabilities: [   0.043265     0.55751     0.39923]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 471, height: 354, ratio: 1.3305084745762712, speed: 42.20452429798461\n",
      "Predicted Class: 1, Probabilities: [   0.043662     0.59263     0.36371]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 469, height: 370, ratio: 1.2675675675675675, speed: 17.867600274797834\n",
      "Predicted Class: 1, Probabilities: [    0.04368     0.59273     0.36359]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 537, height: 395, ratio: 1.3594936708860759, speed: 13.248307833232158\n",
      "Predicted Class: 1, Probabilities: [   0.023078     0.53461     0.44231]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 443, height: 378, ratio: 1.1719576719576719, speed: 71.75326932871685\n",
      "Predicted Class: 1, Probabilities: [   0.018681     0.72363     0.25769]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 463, height: 354, ratio: 1.307909604519774, speed: 17.237341386486058\n",
      "Predicted Class: 1, Probabilities: [   0.038052     0.73953     0.22242]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 411, height: 405, ratio: 1.0148148148148148, speed: 30.137624053318156\n",
      "Predicted Class: 1, Probabilities: [   0.038052     0.73953     0.22242]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 354, height: 392, ratio: 0.9030612244897959, speed: 15.343978857408414\n",
      "Predicted Class: 1, Probabilities: [   0.038052     0.73953     0.22242]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 483, height: 411, ratio: 1.1751824817518248, speed: 35.739215111128516\n",
      "Predicted Class: 1, Probabilities: [   0.023678     0.75958     0.21674]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 489, height: 395, ratio: 1.2379746835443037, speed: 3.5480649666580986\n",
      "Predicted Class: 1, Probabilities: [   0.020051     0.64596     0.33399]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 471, height: 361, ratio: 1.3047091412742382, speed: 83.80972132540428\n",
      "Predicted Class: 1, Probabilities: [   0.026597     0.72061     0.25279]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 516, height: 361, ratio: 1.4293628808864265, speed: 22.324896201769494\n",
      "Predicted Class: 1, Probabilities: [   0.021128     0.70144     0.27743]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 546, height: 391, ratio: 1.3964194373401535, speed: 11.245213070169696\n",
      "Predicted Class: 1, Probabilities: [   0.026816     0.72238      0.2508]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 534, height: 371, ratio: 1.4393530997304582, speed: 32.42277841855936\n",
      "Predicted Class: 1, Probabilities: [   0.026816      0.7224     0.25079]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 518, height: 408, ratio: 1.2696078431372548, speed: 33.36550013232777\n",
      "Predicted Class: 1, Probabilities: [   0.020214     0.64272     0.33706]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 420, height: 388, ratio: 1.0824742268041236, speed: 8.935506506587092\n",
      "Predicted Class: 1, Probabilities: [   0.032792     0.74774     0.21947]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 448, height: 369, ratio: 1.2140921409214092, speed: 7.796082183379056\n",
      "Predicted Class: 1, Probabilities: [   0.038052     0.73953     0.22242]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 519, height: 392, ratio: 1.3239795918367347, speed: 1.0968167361991783\n",
      "Predicted Class: 1, Probabilities: [   0.023768      0.7742     0.20203]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 507, height: 379, ratio: 1.3377308707124012, speed: 123.89206217089097\n",
      "Predicted Class: 2, Probabilities: [   0.017758     0.45331     0.52893]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 521, height: 415, ratio: 1.2554216867469878, speed: 52.89697110573913\n",
      "Predicted Class: 1, Probabilities: [   0.023057     0.53439     0.44255]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 519, height: 394, ratio: 1.3172588832487309, speed: 50.664411838747455\n",
      "Predicted Class: 1, Probabilities: [   0.027854     0.57921     0.39294]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 539, height: 409, ratio: 1.3178484107579462, speed: 36.443346965056975\n",
      "Predicted Class: 1, Probabilities: [   0.023057     0.53439     0.44255]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 523, height: 398, ratio: 1.314070351758794, speed: 32.32799656327519\n",
      "Predicted Class: 1, Probabilities: [   0.023121     0.53505     0.44183]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 516, height: 396, ratio: 1.303030303030303, speed: 26.080633655271438\n",
      "Predicted Class: 1, Probabilities: [   0.023057     0.53439     0.44255]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 545, height: 401, ratio: 1.3591022443890275, speed: 24.53240056681925\n",
      "Predicted Class: 1, Probabilities: [   0.027852     0.57919     0.39296]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 550, height: 403, ratio: 1.3647642679900744, speed: 12.989422512342756\n",
      "Predicted Class: 1, Probabilities: [   0.023057     0.53439     0.44255]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 537, height: 407, ratio: 1.3194103194103195, speed: 19.02549022841706\n",
      "Predicted Class: 1, Probabilities: [   0.027526     0.57642     0.39606]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 531, height: 409, ratio: 1.2982885085574571, speed: 30.8420990040688\n",
      "Predicted Class: 1, Probabilities: [   0.023057     0.53439     0.44255]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 517, height: 406, ratio: 1.2733990147783252, speed: 11.785755542567298\n",
      "Predicted Class: 1, Probabilities: [   0.027187     0.57349     0.39932]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 546, height: 403, ratio: 1.3548387096774193, speed: 4.931647349633118\n",
      "Predicted Class: 1, Probabilities: [    0.02306     0.53443     0.44251]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 532, height: 401, ratio: 1.3266832917705735, speed: 4.7996551957906455\n",
      "Predicted Class: 1, Probabilities: [   0.023057      0.5344     0.44255]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 546, height: 383, ratio: 1.4255874673629243, speed: 37.5424862416446\n",
      "Predicted Class: 1, Probabilities: [   0.023057     0.53439     0.44255]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 533, height: 408, ratio: 1.3063725490196079, speed: 10.519901108435747\n",
      "Predicted Class: 1, Probabilities: [   0.027853     0.57924      0.3929]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 521, height: 405, ratio: 1.2864197530864196, speed: 4.043374548290185\n",
      "Predicted Class: 1, Probabilities: [   0.025462     0.68978     0.28475]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 506, height: 409, ratio: 1.2371638141809291, speed: 21.72760923289945\n",
      "Predicted Class: 1, Probabilities: [   0.027854     0.57921     0.39294]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 502, height: 406, ratio: 1.2364532019704433, speed: 10.500396767977715\n",
      "Predicted Class: 1, Probabilities: [   0.027852      0.5793     0.39284]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 499, height: 411, ratio: 1.2141119221411192, speed: 15.544509879343144\n",
      "Predicted Class: 1, Probabilities: [   0.023062     0.53439     0.44255]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 485, height: 439, ratio: 1.1047835990888382, speed: 24.45381287880794\n",
      "Predicted Class: 1, Probabilities: [   0.027854     0.57921     0.39294]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 480, height: 414, ratio: 1.1594202898550725, speed: 10.427775907954892\n",
      "Predicted Class: 1, Probabilities: [   0.043161     0.54516     0.41168]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 525, height: 338, ratio: 1.5532544378698225, speed: 133.33512707746166\n",
      "Predicted Class: 2, Probabilities: [   0.035882     0.36314     0.60098]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 513, height: 384, ratio: 1.3359375, speed: 103.70909953721299\n",
      "Predicted Class: 2, Probabilities: [   0.017964     0.45753      0.5245]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 490, height: 452, ratio: 1.084070796460177, speed: 58.610859062902314\n",
      "Predicted Class: 1, Probabilities: [   0.027824     0.57895     0.39323]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 490, height: 421, ratio: 1.163895486935867, speed: 92.02276085127762\n",
      "Predicted Class: 1, Probabilities: [   0.023894     0.77236     0.20375]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 504, height: 412, ratio: 1.2233009708737863, speed: 34.723406368100314\n",
      "Predicted Class: 1, Probabilities: [    0.02982     0.62217     0.34801]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 499, height: 402, ratio: 1.2412935323383085, speed: 4.567601562638428\n",
      "Predicted Class: 1, Probabilities: [   0.027854     0.57921     0.39294]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 473, height: 410, ratio: 1.1536585365853658, speed: 9.752377147319557\n",
      "Predicted Class: 1, Probabilities: [   0.027854     0.57921     0.39294]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 499, height: 404, ratio: 1.2351485148514851, speed: 25.575145011368157\n",
      "Predicted Class: 1, Probabilities: [   0.027854     0.57921     0.39294]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 504, height: 396, ratio: 1.2727272727272727, speed: 11.962948470659475\n",
      "Predicted Class: 1, Probabilities: [   0.023086     0.53469     0.44223]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 492, height: 390, ratio: 1.2615384615384615, speed: 6.613294753422008\n",
      "Predicted Class: 1, Probabilities: [   0.027854     0.57921     0.39294]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 493, height: 386, ratio: 1.2772020725388602, speed: 21.49673480804175\n",
      "Predicted Class: 1, Probabilities: [   0.026816      0.7224     0.25078]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 486, height: 379, ratio: 1.2823218997361479, speed: 2.6420505194891755\n",
      "Predicted Class: 1, Probabilities: [   0.028197     0.57773     0.39407]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 474, height: 391, ratio: 1.2122762148337596, speed: 3.973282106926879\n",
      "Predicted Class: 1, Probabilities: [   0.042327     0.68417      0.2735]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 474, height: 384, ratio: 1.234375, speed: 7.846062234714124\n",
      "Predicted Class: 1, Probabilities: [   0.043306     0.61192     0.34478]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 489, height: 381, ratio: 1.2834645669291338, speed: 21.799197512657997\n",
      "Predicted Class: 1, Probabilities: [   0.026816      0.7224     0.25079]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 490, height: 380, ratio: 1.2894736842105263, speed: 3.554295333461321\n",
      "Predicted Class: 1, Probabilities: [   0.026816      0.7224     0.25079]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 502, height: 384, ratio: 1.3072916666666667, speed: 7.513292911847289\n",
      "Predicted Class: 1, Probabilities: [   0.026816      0.7224     0.25079]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 505, height: 382, ratio: 1.3219895287958114, speed: 10.213805157184144\n",
      "Predicted Class: 1, Probabilities: [   0.026816      0.7224     0.25079]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 507, height: 396, ratio: 1.2803030303030303, speed: 7.576833557879364\n",
      "Predicted Class: 1, Probabilities: [   0.023738     0.77635     0.19991]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 487, height: 411, ratio: 1.1849148418491484, speed: 22.253790332812063\n",
      "Predicted Class: 1, Probabilities: [   0.023738     0.77635     0.19991]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 497, height: 387, ratio: 1.2842377260981912, speed: 62.75180422618157\n",
      "Predicted Class: 1, Probabilities: [     0.0242     0.75637     0.21943]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 449, height: 349, ratio: 1.2865329512893984, speed: 6.006775512306775\n",
      "Predicted Class: 1, Probabilities: [   0.039209     0.71748     0.24331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 483, height: 352, ratio: 1.3721590909090908, speed: 11.027807542169935\n",
      "Predicted Class: 1, Probabilities: [   0.042327     0.68419     0.27349]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 503, height: 359, ratio: 1.4011142061281336, speed: 4.427663923075726\n",
      "Predicted Class: 1, Probabilities: [    0.02682     0.72231     0.25087]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 508, height: 369, ratio: 1.3766937669376693, speed: 12.43302461907966\n",
      "Predicted Class: 1, Probabilities: [   0.026816      0.7224     0.25079]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 510, height: 375, ratio: 1.36, speed: 9.425152053159785\n",
      "Predicted Class: 1, Probabilities: [   0.026816      0.7224     0.25079]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 474, height: 350, ratio: 1.3542857142857143, speed: 9.558517656810919\n",
      "Predicted Class: 1, Probabilities: [   0.042301     0.68423     0.27347]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 488, height: 358, ratio: 1.3631284916201116, speed: 2.320565378462131\n",
      "Predicted Class: 1, Probabilities: [   0.026816      0.7224     0.25079]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 385, height: 349, ratio: 1.1031518624641834, speed: 32.02999995592523\n",
      "Predicted Class: 1, Probabilities: [   0.038052     0.73953     0.22242]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 403, height: 326, ratio: 1.2361963190184049, speed: 6.886254346854215\n",
      "Predicted Class: 1, Probabilities: [   0.038052     0.73953     0.22242]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 460, height: 368, ratio: 1.25, speed: 39.15922107308388\n",
      "Predicted Class: 1, Probabilities: [   0.042314     0.68436     0.27333]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 469, height: 384, ratio: 1.2213541666666667, speed: 7.340041955528415\n",
      "Predicted Class: 1, Probabilities: [   0.026816      0.7224     0.25079]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 434, height: 393, ratio: 1.104325699745547, speed: 28.82128201070896\n",
      "Predicted Class: 1, Probabilities: [   0.042315     0.68422     0.27346]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 466, height: 402, ratio: 1.1592039800995024, speed: 20.002741802457933\n",
      "Predicted Class: 1, Probabilities: [   0.027857      0.5792     0.39295]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 468, height: 404, ratio: 1.1584158415841583, speed: 4.679218685188986\n",
      "Predicted Class: 1, Probabilities: [   0.028175     0.57781     0.39401]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 446, height: 395, ratio: 1.129113924050633, speed: 6.242201486122717\n",
      "Predicted Class: 1, Probabilities: [   0.043174     0.54507     0.41175]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 469, height: 402, ratio: 1.1666666666666667, speed: 2.9651260462474576\n",
      "Predicted Class: 1, Probabilities: [   0.027854     0.57921     0.39294]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 490, height: 403, ratio: 1.215880893300248, speed: 9.182726514692362\n",
      "Predicted Class: 1, Probabilities: [   0.026817     0.72235     0.25083]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 510, height: 402, ratio: 1.2686567164179106, speed: 5.894441799970179\n",
      "Predicted Class: 1, Probabilities: [   0.026822     0.72211     0.25107]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 501, height: 402, ratio: 1.2462686567164178, speed: 3.816640170995044\n",
      "Predicted Class: 1, Probabilities: [   0.029819     0.62217     0.34801]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 496, height: 401, ratio: 1.2369077306733167, speed: 10.334444533055644\n",
      "Predicted Class: 1, Probabilities: [   0.027857      0.5793     0.39284]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 514, height: 400, ratio: 1.285, speed: 6.716738964703216\n",
      "Predicted Class: 1, Probabilities: [   0.027893      0.5804     0.39171]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 512, height: 399, ratio: 1.2832080200501252, speed: 2.3716210389160497\n",
      "Predicted Class: 1, Probabilities: [   0.029054     0.60842     0.36253]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 416, height: 398, ratio: 1.0452261306532664, speed: 2.9745965925228455\n",
      "Predicted Class: 1, Probabilities: [   0.043674       0.593     0.36332]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 491, height: 393, ratio: 1.2493638676844783, speed: 16.60549818303956\n",
      "Predicted Class: 1, Probabilities: [   0.026808     0.72256     0.25063]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 498, height: 389, ratio: 1.2802056555269923, speed: 9.332999022995374\n",
      "Predicted Class: 1, Probabilities: [   0.026736     0.72402     0.24924]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 496, height: 392, ratio: 1.2653061224489797, speed: 20.76242256596296\n",
      "Predicted Class: 1, Probabilities: [   0.023744     0.77625         0.2]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 498, height: 385, ratio: 1.2935064935064935, speed: 25.278018561953754\n",
      "Predicted Class: 1, Probabilities: [     0.0242     0.75637     0.21943]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 502, height: 387, ratio: 1.297157622739018, speed: 4.955676081145265\n",
      "Predicted Class: 1, Probabilities: [   0.023738     0.77635     0.19991]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 502, height: 373, ratio: 1.3458445040214477, speed: 3.2440444504753043\n",
      "Predicted Class: 1, Probabilities: [   0.026816      0.7224     0.25079]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 506, height: 385, ratio: 1.3142857142857143, speed: 6.532673214469502\n",
      "Predicted Class: 1, Probabilities: [   0.026816      0.7224     0.25079]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 509, height: 386, ratio: 1.3186528497409327, speed: 25.109615273871405\n",
      "Predicted Class: 1, Probabilities: [   0.024224     0.75558      0.2202]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 512, height: 384, ratio: 1.3333333333333333, speed: 6.174496988715436\n",
      "Predicted Class: 1, Probabilities: [   0.024224     0.75558      0.2202]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 512, height: 384, ratio: 1.3333333333333333, speed: 5.556127312905413\n",
      "Predicted Class: 1, Probabilities: [   0.024224     0.75558      0.2202]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 513, height: 385, ratio: 1.3324675324675326, speed: 31.0290120321115\n",
      "Predicted Class: 1, Probabilities: [   0.024224     0.75558      0.2202]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 514, height: 374, ratio: 1.374331550802139, speed: 0.5841618813076335\n",
      "Predicted Class: 1, Probabilities: [   0.023738     0.77635     0.19991]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 514, height: 377, ratio: 1.363395225464191, speed: 3.7517830665395535\n",
      "Predicted Class: 1, Probabilities: [   0.023738     0.77635     0.19991]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 516, height: 377, ratio: 1.3687002652519893, speed: 8.02272933546616\n",
      "Predicted Class: 1, Probabilities: [   0.023738     0.77633     0.19993]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 521, height: 378, ratio: 1.3783068783068784, speed: 20.320170159215586\n",
      "Predicted Class: 1, Probabilities: [   0.024223     0.75562     0.22016]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 505, height: 387, ratio: 1.3049095607235142, speed: 29.762817021766416\n",
      "Predicted Class: 1, Probabilities: [   0.024228     0.75557     0.22021]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 497, height: 373, ratio: 1.3324396782841823, speed: 20.908902235847385\n",
      "Predicted Class: 1, Probabilities: [   0.024224     0.75558      0.2202]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 502, height: 380, ratio: 1.3210526315789475, speed: 3.404006416029255\n",
      "Predicted Class: 1, Probabilities: [   0.024224     0.75558      0.2202]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 507, height: 377, ratio: 1.3448275862068966, speed: 7.774090025627528\n",
      "Predicted Class: 1, Probabilities: [   0.024224     0.75558      0.2202]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 503, height: 400, ratio: 1.2575, speed: 9.823309419656017\n",
      "Predicted Class: 1, Probabilities: [   0.024224     0.75558      0.2202]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 504, height: 384, ratio: 1.3125, speed: 6.937810436855063\n",
      "Predicted Class: 1, Probabilities: [   0.024224     0.75558      0.2202]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 497, height: 379, ratio: 1.3113456464379947, speed: 5.200926426534606\n",
      "Predicted Class: 1, Probabilities: [   0.024224     0.75558      0.2202]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 496, height: 370, ratio: 1.3405405405405406, speed: 27.585720625060436\n",
      "Predicted Class: 1, Probabilities: [   0.024224     0.75558      0.2202]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 496, height: 373, ratio: 1.3297587131367292, speed: 17.286228893713204\n",
      "Predicted Class: 1, Probabilities: [   0.024224     0.75558      0.2202]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 494, height: 388, ratio: 1.2731958762886597, speed: 34.52467502681187\n",
      "Predicted Class: 1, Probabilities: [   0.024224     0.75558      0.2202]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 509, height: 387, ratio: 1.3152454780361758, speed: 7.46762875082032\n",
      "Predicted Class: 1, Probabilities: [   0.024224     0.75558      0.2202]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 507, height: 385, ratio: 1.316883116883117, speed: 31.996762338943785\n",
      "Predicted Class: 1, Probabilities: [   0.029765     0.62411     0.34613]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 507, height: 383, ratio: 1.3237597911227155, speed: 2.988291532682327\n",
      "Predicted Class: 1, Probabilities: [    0.02982     0.62217     0.34801]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 499, height: 397, ratio: 1.256926952141058, speed: 11.898990454951702\n",
      "Predicted Class: 1, Probabilities: [    0.02982     0.62217     0.34801]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 497, height: 395, ratio: 1.2582278481012659, speed: 9.46884164734282\n",
      "Predicted Class: 1, Probabilities: [    0.02982     0.62217     0.34801]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 498, height: 396, ratio: 1.2575757575757576, speed: 3.0450257004899313\n",
      "Predicted Class: 1, Probabilities: [   0.029819     0.62217     0.34801]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 506, height: 392, ratio: 1.2908163265306123, speed: 1.039159632373454\n",
      "Predicted Class: 1, Probabilities: [    0.02982     0.62218     0.34801]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 506, height: 387, ratio: 1.3074935400516796, speed: 52.37033984214501\n",
      "Predicted Class: 1, Probabilities: [   0.023982     0.76409     0.21193]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 507, height: 392, ratio: 1.2933673469387754, speed: 1.8779660441303598\n",
      "Predicted Class: 1, Probabilities: [   0.024224     0.75558      0.2202]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 391, height: 394, ratio: 0.9923857868020305, speed: 32.286395239009515\n",
      "Predicted Class: 1, Probabilities: [   0.038053     0.73952     0.22243]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 435, height: 380, ratio: 1.144736842105263, speed: 2.9410504624026124\n",
      "Predicted Class: 1, Probabilities: [   0.039214     0.71736     0.24343]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 441, height: 372, ratio: 1.185483870967742, speed: 31.477493268684324\n",
      "Predicted Class: 1, Probabilities: [   0.038052     0.73953     0.22242]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 478, height: 357, ratio: 1.3389355742296918, speed: 7.31135487611337\n",
      "Predicted Class: 1, Probabilities: [   0.039214     0.71736     0.24343]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 479, height: 391, ratio: 1.225063938618926, speed: 22.809714911322654\n",
      "Predicted Class: 1, Probabilities: [   0.024224     0.75558      0.2202]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 488, height: 359, ratio: 1.3593314763231197, speed: 6.893396347488828\n",
      "Predicted Class: 1, Probabilities: [   0.024224     0.75558      0.2202]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 501, height: 365, ratio: 1.3726027397260274, speed: 28.654301829804087\n",
      "Predicted Class: 1, Probabilities: [   0.029823     0.62216     0.34802]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 498, height: 376, ratio: 1.324468085106383, speed: 21.080509062579683\n",
      "Predicted Class: 1, Probabilities: [    0.04368     0.59273     0.36359]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 496, height: 385, ratio: 1.2883116883116883, speed: 17.477691378980293\n",
      "Predicted Class: 1, Probabilities: [    0.04368     0.59273     0.36359]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 495, height: 380, ratio: 1.3026315789473684, speed: 12.460208584775293\n",
      "Predicted Class: 1, Probabilities: [    0.03865     0.60031     0.36104]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 495, height: 366, ratio: 1.3524590163934427, speed: 11.3331509218905\n",
      "Predicted Class: 1, Probabilities: [   0.029816      0.6223     0.34789]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 494, height: 367, ratio: 1.3460490463215258, speed: 4.246667471138797\n",
      "Predicted Class: 1, Probabilities: [   0.026816      0.7224     0.25079]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 495, height: 373, ratio: 1.3270777479892761, speed: 16.82545483338933\n",
      "Predicted Class: 1, Probabilities: [   0.026816      0.7224     0.25079]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 508, height: 389, ratio: 1.3059125964010283, speed: 5.9343129804702235\n",
      "Predicted Class: 1, Probabilities: [   0.026816      0.7224     0.25079]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 507, height: 383, ratio: 1.3237597911227155, speed: 9.948630208881934\n",
      "Predicted Class: 1, Probabilities: [   0.026816      0.7224     0.25079]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 510, height: 384, ratio: 1.328125, speed: 6.198950706232006\n",
      "Predicted Class: 1, Probabilities: [   0.029805     0.62262     0.34757]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 508, height: 388, ratio: 1.309278350515464, speed: 2.147257067035074\n",
      "Predicted Class: 1, Probabilities: [   0.026816      0.7224     0.25079]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 512, height: 388, ratio: 1.3195876288659794, speed: 2.293960010079141\n",
      "Predicted Class: 1, Probabilities: [    0.02982     0.62217     0.34801]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 485, height: 390, ratio: 1.2435897435897436, speed: 12.039178744924033\n",
      "Predicted Class: 1, Probabilities: [   0.026815      0.7224     0.25078]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 494, height: 389, ratio: 1.2699228791773778, speed: 0.8470643049838468\n",
      "Predicted Class: 1, Probabilities: [   0.023738     0.77635     0.19991]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 492, height: 380, ratio: 1.2947368421052632, speed: 0.6173752173903768\n",
      "Predicted Class: 1, Probabilities: [   0.029819     0.62219     0.34799]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 495, height: 387, ratio: 1.2790697674418605, speed: 8.194400937311578\n",
      "Predicted Class: 1, Probabilities: [   0.024186     0.76179     0.21403]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 502, height: 380, ratio: 1.3210526315789475, speed: 11.012569120381057\n",
      "Predicted Class: 1, Probabilities: [   0.027854     0.57921     0.39294]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 504, height: 383, ratio: 1.3159268929503916, speed: 34.224433807840605\n",
      "Predicted Class: 1, Probabilities: [   0.024875     0.74326     0.23187]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 510, height: 386, ratio: 1.3212435233160622, speed: 6.587258386394559\n",
      "Predicted Class: 1, Probabilities: [   0.026834     0.72161     0.25155]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 512, height: 385, ratio: 1.3298701298701299, speed: 1.50970458984375\n",
      "Predicted Class: 1, Probabilities: [   0.026816     0.72237     0.25082]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 535, height: 385, ratio: 1.3896103896103895, speed: 17.509863658166932\n",
      "Predicted Class: 1, Probabilities: [   0.026618     0.70545     0.26793]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 541, height: 374, ratio: 1.446524064171123, speed: 7.60460336569404\n",
      "Predicted Class: 1, Probabilities: [    0.02982     0.62217     0.34801]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 519, height: 385, ratio: 1.348051948051948, speed: 6.0819845315231795\n",
      "Predicted Class: 1, Probabilities: [    0.02982     0.62217     0.34801]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 511, height: 381, ratio: 1.3412073490813647, speed: 13.733422717228123\n",
      "Predicted Class: 1, Probabilities: [   0.029797     0.62285     0.34735]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 513, height: 381, ratio: 1.3464566929133859, speed: 34.06171685012266\n",
      "Predicted Class: 1, Probabilities: [   0.024224     0.75558      0.2202]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 505, height: 383, ratio: 1.318537859007833, speed: 7.664333578471911\n",
      "Predicted Class: 1, Probabilities: [   0.024224     0.75558      0.2202]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 498, height: 382, ratio: 1.3036649214659686, speed: 30.60483488097088\n",
      "Predicted Class: 1, Probabilities: [   0.024224     0.75558      0.2202]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 501, height: 385, ratio: 1.3012987012987014, speed: 65.11483793852292\n",
      "Predicted Class: 1, Probabilities: [   0.027703     0.68611     0.28619]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 496, height: 407, ratio: 1.2186732186732188, speed: 21.68015695397868\n",
      "Predicted Class: 1, Probabilities: [   0.024224     0.75558      0.2202]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 490, height: 404, ratio: 1.2128712871287128, speed: 22.651496353637935\n",
      "Predicted Class: 1, Probabilities: [   0.024224     0.75558      0.2202]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 492, height: 393, ratio: 1.251908396946565, speed: 40.80013591027005\n",
      "Predicted Class: 1, Probabilities: [   0.023676     0.75962     0.21671]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 469, height: 354, ratio: 1.3248587570621468, speed: 15.430357152355844\n",
      "Predicted Class: 1, Probabilities: [   0.038052     0.73953     0.22242]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 489, height: 388, ratio: 1.2603092783505154, speed: 16.84421311025038\n",
      "Predicted Class: 1, Probabilities: [   0.038052     0.73953     0.22242]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 506, height: 423, ratio: 1.1962174940898345, speed: 20.328878938723594\n",
      "Predicted Class: 1, Probabilities: [   0.026651     0.71785      0.2555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 394, height: 426, ratio: 0.9248826291079812, speed: 15.52222566539949\n",
      "Predicted Class: 1, Probabilities: [   0.028814     0.65997     0.31122]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 471, height: 432, ratio: 1.0902777777777777, speed: 11.900575747656186\n",
      "Predicted Class: 1, Probabilities: [   0.026661     0.71769     0.25565]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 523, height: 446, ratio: 1.1726457399103138, speed: 12.533231970175247\n",
      "Predicted Class: 2, Probabilities: [    0.02445     0.40641     0.56914]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 576, height: 445, ratio: 1.29438202247191, speed: 7.001447978339898\n",
      "Predicted Class: 2, Probabilities: [   0.023846     0.20043     0.77573]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 552, height: 474, ratio: 1.1645569620253164, speed: 22.827863803142375\n",
      "Predicted Class: 2, Probabilities: [   0.024027     0.21928     0.75669]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 491, height: 459, ratio: 1.0697167755991286, speed: 4.483284615044752\n",
      "Predicted Class: 1, Probabilities: [   0.029655     0.63306     0.33728]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 477, height: 482, ratio: 0.9896265560165975, speed: 16.93107691450095\n",
      "Predicted Class: 1, Probabilities: [   0.023676     0.75962     0.21671]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 458, height: 487, ratio: 0.9404517453798767, speed: 14.419974375996608\n",
      "Predicted Class: 1, Probabilities: [   0.026217     0.72438      0.2494]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 441, height: 501, ratio: 0.8802395209580839, speed: 22.43606872562461\n",
      "Predicted Class: 1, Probabilities: [   0.023677      0.7596     0.21672]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 442, height: 516, ratio: 0.8565891472868217, speed: 9.731363955801172\n",
      "Predicted Class: 1, Probabilities: [   0.023676     0.75962     0.21671]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 439, height: 524, ratio: 0.8377862595419847, speed: 6.071841772148475\n",
      "Predicted Class: 1, Probabilities: [   0.023676     0.75962     0.21671]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 423, height: 543, ratio: 0.7790055248618785, speed: 10.56546555583241\n",
      "Predicted Class: 1, Probabilities: [   0.023676     0.75962     0.21671]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 403, height: 550, ratio: 0.7327272727272728, speed: 6.988316010147168\n",
      "Predicted Class: 1, Probabilities: [   0.023676     0.75962     0.21671]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 391, height: 560, ratio: 0.6982142857142857, speed: 4.273904982392933\n",
      "Predicted Class: 1, Probabilities: [   0.023676     0.75962     0.21671]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 378, height: 573, ratio: 0.6596858638743456, speed: 8.923880707945505\n",
      "Predicted Class: 1, Probabilities: [   0.023798     0.75802     0.21818]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 370, height: 584, ratio: 0.6335616438356164, speed: 7.601655277645667\n",
      "Predicted Class: 1, Probabilities: [   0.026542     0.71951     0.25395]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 359, height: 591, ratio: 0.6074450084602369, speed: 5.407392167006907\n",
      "Predicted Class: 1, Probabilities: [   0.026659     0.71772     0.25562]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 347, height: 599, ratio: 0.5792988313856428, speed: 11.312237492674182\n",
      "Predicted Class: 1, Probabilities: [   0.026659     0.71772     0.25562]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 335, height: 611, ratio: 0.5482815057283142, speed: 10.751819385035041\n",
      "Predicted Class: 1, Probabilities: [   0.026659     0.71772     0.25562]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 326, height: 619, ratio: 0.5266558966074314, speed: 8.365667686508322\n",
      "Predicted Class: 1, Probabilities: [   0.026659     0.71772     0.25562]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 314, height: 628, ratio: 0.5, speed: 6.5388268984706\n",
      "Predicted Class: 1, Probabilities: [   0.026659     0.71772     0.25562]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 305, height: 640, ratio: 0.4765625, speed: 8.706761279912985\n",
      "Predicted Class: 1, Probabilities: [   0.026659     0.71772     0.25562]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 296, height: 647, ratio: 0.4574961360123648, speed: 8.610952095427278\n",
      "Predicted Class: 1, Probabilities: [   0.026659     0.71772     0.25562]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 279, height: 654, ratio: 0.42660550458715596, speed: 8.895344304352475\n",
      "Predicted Class: 1, Probabilities: [   0.026659     0.71772     0.25562]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 265, height: 665, ratio: 0.39849624060150374, speed: 10.618621663271366\n",
      "Predicted Class: 1, Probabilities: [   0.026663      0.7175     0.25583]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 255, height: 666, ratio: 0.38288288288288286, speed: 9.656294993367453\n",
      "Predicted Class: 1, Probabilities: [   0.027121     0.69339     0.27949]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 249, height: 675, ratio: 0.3688888888888889, speed: 6.1408604519847785\n",
      "Predicted Class: 1, Probabilities: [   0.027967      0.6538     0.31823]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 243, height: 680, ratio: 0.3573529411764706, speed: 8.645154982409867\n",
      "Predicted Class: 1, Probabilities: [   0.028998     0.60569     0.36532]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 233, height: 681, ratio: 0.342143906020558, speed: 6.7195088519619715\n",
      "Predicted Class: 1, Probabilities: [   0.027912     0.65631     0.31577]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 233, height: 684, ratio: 0.3406432748538012, speed: 9.358104150328144\n",
      "Predicted Class: 1, Probabilities: [   0.027587     0.67127     0.30114]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 246, height: 683, ratio: 0.3601756954612006, speed: 5.959127832701963\n",
      "Predicted Class: 1, Probabilities: [   0.027587     0.67127     0.30114]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 258, height: 689, ratio: 0.37445573294629897, speed: 6.211183328595888\n",
      "Predicted Class: 1, Probabilities: [   0.027587     0.67127     0.30114]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 270, height: 694, ratio: 0.38904899135446686, speed: 7.998437152579105\n",
      "Predicted Class: 1, Probabilities: [   0.027587     0.67127     0.30114]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 275, height: 694, ratio: 0.3962536023054755, speed: 6.854698919959618\n",
      "Predicted Class: 1, Probabilities: [   0.027587     0.67127     0.30114]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 285, height: 696, ratio: 0.40948275862068967, speed: 5.607581572631796\n",
      "Predicted Class: 1, Probabilities: [   0.027587     0.67127     0.30114]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 306, height: 695, ratio: 0.44028776978417267, speed: 4.292415663553605\n",
      "Predicted Class: 1, Probabilities: [   0.027587     0.67127     0.30114]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 316, height: 691, ratio: 0.4573082489146165, speed: 6.9311710068191035\n",
      "Predicted Class: 1, Probabilities: [   0.027587     0.67127     0.30114]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 332, height: 689, ratio: 0.4818577648766328, speed: 7.581856760173807\n",
      "Predicted Class: 1, Probabilities: [    0.02106     0.77445     0.20449]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 336, height: 682, ratio: 0.49266862170087977, speed: 9.205860436418007\n",
      "Predicted Class: 1, Probabilities: [   0.024663     0.72474      0.2506]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 347, height: 679, ratio: 0.5110456553755522, speed: 8.310106248004601\n",
      "Predicted Class: 1, Probabilities: [   0.021399     0.77024     0.20836]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 352, height: 680, ratio: 0.5176470588235295, speed: 5.745519909734456\n",
      "Predicted Class: 1, Probabilities: [   0.020924     0.77613     0.20295]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 350, height: 680, ratio: 0.5147058823529411, speed: 12.720374945687754\n",
      "Predicted Class: 1, Probabilities: [   0.020924     0.77613     0.20295]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 365, height: 681, ratio: 0.5359765051395007, speed: 4.214549616541668\n",
      "Predicted Class: 1, Probabilities: [   0.020924     0.77613     0.20295]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 359, height: 681, ratio: 0.527165932452276, speed: 9.706005915840942\n",
      "Predicted Class: 1, Probabilities: [   0.020924     0.77613     0.20295]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 356, height: 680, ratio: 0.5235294117647059, speed: 8.299976796958877\n",
      "Predicted Class: 1, Probabilities: [   0.020925     0.77613     0.20295]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 353, height: 676, ratio: 0.522189349112426, speed: 6.522859426027282\n",
      "Predicted Class: 1, Probabilities: [   0.020937     0.77612     0.20295]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 357, height: 664, ratio: 0.5376506024096386, speed: 8.578337510175052\n",
      "Predicted Class: 1, Probabilities: [   0.032171     0.76365     0.20418]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 352, height: 656, ratio: 0.5365853658536586, speed: 10.250637174876141\n",
      "Predicted Class: 1, Probabilities: [   0.032222     0.76362     0.20416]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 350, height: 663, ratio: 0.5279034690799397, speed: 9.71498214800749\n",
      "Predicted Class: 1, Probabilities: [   0.033324     0.75033     0.21635]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 329, height: 663, ratio: 0.4962292609351433, speed: 8.919435214649011\n",
      "Predicted Class: 1, Probabilities: [   0.032794     0.72664     0.24057]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 313, height: 656, ratio: 0.4771341463414634, speed: 4.133934986933051\n",
      "Predicted Class: 1, Probabilities: [   0.032384     0.70847     0.25914]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 293, height: 655, ratio: 0.44732824427480916, speed: 1.9872487959196878\n",
      "Predicted Class: 1, Probabilities: [   0.043236     0.54619     0.41057]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 284, height: 654, ratio: 0.43425076452599387, speed: 6.516003707188532\n",
      "Predicted Class: 1, Probabilities: [   0.043235     0.54618     0.41058]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 279, height: 654, ratio: 0.42660550458715596, speed: 6.444673503034746\n",
      "Predicted Class: 1, Probabilities: [   0.043235     0.54618     0.41058]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 263, height: 656, ratio: 0.4009146341463415, speed: 7.162678132310167\n",
      "Predicted Class: 1, Probabilities: [   0.043235     0.54618     0.41058]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 231, height: 656, ratio: 0.3521341463414634, speed: 9.748782917648745\n",
      "Predicted Class: 1, Probabilities: [   0.043235     0.54618     0.41058]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 215, height: 656, ratio: 0.3277439024390244, speed: 10.585620311159987\n",
      "Predicted Class: 1, Probabilities: [   0.043235     0.54618     0.41058]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 209, height: 653, ratio: 0.32006125574272587, speed: 9.555784221354594\n",
      "Predicted Class: 1, Probabilities: [   0.043235     0.54618     0.41058]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 206, height: 662, ratio: 0.311178247734139, speed: 11.649149979645655\n",
      "Predicted Class: 1, Probabilities: [   0.043235     0.54618     0.41058]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 197, height: 659, ratio: 0.29893778452200304, speed: 11.962451749109523\n",
      "Predicted Class: 1, Probabilities: [   0.043235     0.54618     0.41058]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 193, height: 656, ratio: 0.2942073170731707, speed: 8.943833807669566\n",
      "Predicted Class: 1, Probabilities: [   0.043235     0.54618     0.41058]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 184, height: 652, ratio: 0.2822085889570552, speed: 5.937183725141554\n",
      "Predicted Class: 1, Probabilities: [   0.043235     0.54618     0.41058]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 183, height: 650, ratio: 0.2815384615384615, speed: 6.324551637843066\n",
      "Predicted Class: 1, Probabilities: [   0.043235     0.54618     0.41058]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 185, height: 644, ratio: 0.28726708074534163, speed: 11.046849117422022\n",
      "Predicted Class: 1, Probabilities: [   0.043235     0.54618     0.41058]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 181, height: 642, ratio: 0.2819314641744548, speed: 9.86619311895785\n",
      "Predicted Class: 1, Probabilities: [   0.043235     0.54618     0.41058]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 181, height: 634, ratio: 0.2854889589905363, speed: 6.256388597978364\n",
      "Predicted Class: 1, Probabilities: [   0.043235     0.54618     0.41058]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 186, height: 632, ratio: 0.29430379746835444, speed: 9.155319541025309\n",
      "Predicted Class: 1, Probabilities: [   0.043235     0.54618     0.41058]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 191, height: 627, ratio: 0.30462519936204147, speed: 7.4149445332204085\n",
      "Predicted Class: 1, Probabilities: [   0.043235     0.54618     0.41058]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 195, height: 625, ratio: 0.312, speed: 9.693906640023005\n",
      "Predicted Class: 1, Probabilities: [   0.043235     0.54618     0.41058]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 196, height: 624, ratio: 0.3141025641025641, speed: 4.488799244783524\n",
      "Predicted Class: 1, Probabilities: [   0.043215     0.54646     0.41032]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 194, height: 615, ratio: 0.3154471544715447, speed: 8.000589375469294\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61576     0.34556]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 195, height: 615, ratio: 0.3170731707317073, speed: 9.776612430392998\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 176, height: 614, ratio: 0.28664495114006516, speed: 6.600545293959618\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 182, height: 613, ratio: 0.2969004893964111, speed: 7.964047384151662\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 187, height: 610, ratio: 0.30655737704918035, speed: 4.222273654275912\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 189, height: 611, ratio: 0.309328968903437, speed: 5.876189132029398\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 197, height: 618, ratio: 0.3187702265372168, speed: 8.714270913079693\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 204, height: 615, ratio: 0.33170731707317075, speed: 7.823204703903462\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 210, height: 615, ratio: 0.34146341463414637, speed: 6.480113852398644\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 205, height: 615, ratio: 0.3333333333333333, speed: 5.773710228356128\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 203, height: 621, ratio: 0.32689210950080516, speed: 7.054089921233186\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 202, height: 623, ratio: 0.32423756019261635, speed: 4.964006049542716\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 208, height: 631, ratio: 0.329635499207607, speed: 5.647268258206236\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 212, height: 638, ratio: 0.3322884012539185, speed: 7.60826873301448\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 217, height: 643, ratio: 0.33748055987558323, speed: 6.890742692106156\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 225, height: 645, ratio: 0.3488372093023256, speed: 4.403364138955972\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 232, height: 639, ratio: 0.36306729264475746, speed: 6.565465271673243\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 243, height: 636, ratio: 0.38207547169811323, speed: 1.6489276544977043\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 245, height: 633, ratio: 0.38704581358609796, speed: 3.9003352846649824\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 253, height: 636, ratio: 0.3977987421383648, speed: 5.897213087640223\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 255, height: 644, ratio: 0.39596273291925466, speed: 2.2398605502458624\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 254, height: 635, ratio: 0.4, speed: 7.310337834772182\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 253, height: 589, ratio: 0.4295415959252971, speed: 5.637671706455878\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 256, height: 585, ratio: 0.4376068376068376, speed: 10.126748373423473\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 252, height: 591, ratio: 0.4263959390862944, speed: 9.126621517923072\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 247, height: 607, ratio: 0.40691927512355847, speed: 10.497994611754352\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 252, height: 607, ratio: 0.41515650741350907, speed: 9.181283582806467\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 250, height: 606, ratio: 0.41254125412541254, speed: 6.602472333534251\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 260, height: 590, ratio: 0.4406779661016949, speed: 8.142482037519317\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 264, height: 574, ratio: 0.45993031358885017, speed: 7.217009569686144\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 257, height: 550, ratio: 0.4672727272727273, speed: 13.89699714639896\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 268, height: 533, ratio: 0.5028142589118199, speed: 8.090130574331045\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 259, height: 512, ratio: 0.505859375, speed: 8.362985869076486\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 269, height: 487, ratio: 0.5523613963039015, speed: 6.820301504395235\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 254, height: 472, ratio: 0.538135593220339, speed: 3.691175317060126\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 268, height: 461, ratio: 0.5813449023861171, speed: 6.11457051022709\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 264, height: 455, ratio: 0.5802197802197803, speed: 7.531096510851839\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 258, height: 443, ratio: 0.582392776523702, speed: 6.697924552977989\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34554]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 264, height: 433, ratio: 0.6096997690531177, speed: 7.196596812841177\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34554]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 282, height: 435, ratio: 0.6482758620689655, speed: 1.2796543268485592\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 290, height: 434, ratio: 0.6682027649769585, speed: 1.9795200894892873\n",
      "Predicted Class: 1, Probabilities: [   0.041824     0.63778     0.32039]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 293, height: 426, ratio: 0.687793427230047, speed: 4.66566022214639\n",
      "Predicted Class: 1, Probabilities: [   0.038967     0.61798     0.34305]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 283, height: 426, ratio: 0.6643192488262911, speed: 2.807914343390061\n",
      "Predicted Class: 1, Probabilities: [   0.039798      0.6241     0.33611]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 273, height: 433, ratio: 0.6304849884526559, speed: 3.8509335401670675\n",
      "Predicted Class: 1, Probabilities: [   0.038959     0.61792     0.34313]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 293, height: 434, ratio: 0.6751152073732719, speed: 3.472143836682748\n",
      "Predicted Class: 1, Probabilities: [   0.042845     0.64406     0.31309]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 300, height: 434, ratio: 0.6912442396313364, speed: 3.9510999040435735\n",
      "Predicted Class: 1, Probabilities: [   0.042542     0.64224     0.31522]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 270, height: 437, ratio: 0.6178489702517163, speed: 3.977207888048823\n",
      "Predicted Class: 1, Probabilities: [   0.043038      0.6452     0.31176]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 276, height: 439, ratio: 0.6287015945330297, speed: 0.9590558341234365\n",
      "Predicted Class: 1, Probabilities: [   0.043254     0.64647     0.31028]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 263, height: 443, ratio: 0.5936794582392777, speed: 3.6264057132815433\n",
      "Predicted Class: 1, Probabilities: [   0.042602      0.6426      0.3148]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 304, height: 451, ratio: 0.6740576496674058, speed: 4.373999185411266\n",
      "Predicted Class: 1, Probabilities: [   0.038884     0.61735     0.34377]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 268, height: 459, ratio: 0.5838779956427015, speed: 4.654186546451596\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 303, height: 467, ratio: 0.6488222698072805, speed: 0.9609049468380212\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 321, height: 481, ratio: 0.6673596673596673, speed: 2.815130180695301\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 325, height: 490, ratio: 0.6632653061224489, speed: 2.539810693555347\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 325, height: 493, ratio: 0.6592292089249493, speed: 2.275787831305474\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 327, height: 498, ratio: 0.6566265060240963, speed: 0.8870326697566897\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 326, height: 498, ratio: 0.6546184738955824, speed: 1.961073112843823\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 326, height: 503, ratio: 0.6481113320079522, speed: 0.8249933326437645\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 324, height: 512, ratio: 0.6328125, speed: 2.4022615705502233\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 322, height: 520, ratio: 0.6192307692307693, speed: 1.154119645553563\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 322, height: 524, ratio: 0.6145038167938931, speed: 2.255274569655031\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 321, height: 521, ratio: 0.6161228406909789, speed: 2.5068450983654325\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 316, height: 524, ratio: 0.6030534351145038, speed: 3.6011406884281967\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 312, height: 526, ratio: 0.5931558935361216, speed: 3.1265824558707718\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 309, height: 528, ratio: 0.5852272727272727, speed: 2.8491978886168847\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 308, height: 532, ratio: 0.5789473684210527, speed: 1.6923737631590938\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 299, height: 533, ratio: 0.5609756097560976, speed: 2.4441728832112384\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 296, height: 536, ratio: 0.5522388059701493, speed: 3.1112989452729014\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 291, height: 535, ratio: 0.5439252336448598, speed: 2.6171085457043235\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 283, height: 540, ratio: 0.524074074074074, speed: 2.055605684563651\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 278, height: 538, ratio: 0.516728624535316, speed: 1.3505726489365855\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 270, height: 531, ratio: 0.5084745762711864, speed: 4.6844946255309905\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34554]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 267, height: 518, ratio: 0.5154440154440154, speed: 5.976522718085707\n",
      "Predicted Class: 1, Probabilities: [   0.043267     0.64654     0.31019]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 259, height: 502, ratio: 0.5159362549800797, speed: 4.77590163603848\n",
      "Predicted Class: 1, Probabilities: [   0.043297     0.64672     0.30999]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 243, height: 490, ratio: 0.4959183673469388, speed: 3.461065713895039\n",
      "Predicted Class: 1, Probabilities: [   0.043297     0.64672     0.30999]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 245, height: 485, ratio: 0.5051546391752577, speed: 5.057736622681106\n",
      "Predicted Class: 1, Probabilities: [   0.043297     0.64672     0.30999]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 246, height: 473, ratio: 0.5200845665961945, speed: 3.9267942504377302\n",
      "Predicted Class: 1, Probabilities: [   0.043297     0.64672     0.30999]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 237, height: 465, ratio: 0.5096774193548387, speed: 4.764323039011036\n",
      "Predicted Class: 1, Probabilities: [   0.043297     0.64672     0.30999]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 237, height: 455, ratio: 0.5208791208791209, speed: 3.329811884417826\n",
      "Predicted Class: 1, Probabilities: [   0.043297     0.64672     0.30999]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 235, height: 452, ratio: 0.5199115044247787, speed: 5.790339099118723\n",
      "Predicted Class: 1, Probabilities: [   0.043297     0.64672     0.30999]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 213, height: 442, ratio: 0.4819004524886878, speed: 7.151051557420324\n",
      "Predicted Class: 1, Probabilities: [   0.043297     0.64672     0.30999]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 184, height: 444, ratio: 0.4144144144144144, speed: 1.2137334938304678\n",
      "Predicted Class: 1, Probabilities: [   0.043297     0.64672     0.30999]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 171, height: 441, ratio: 0.3877551020408163, speed: 1.5542583687750913\n",
      "Predicted Class: 1, Probabilities: [   0.043297     0.64672     0.30999]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 151, height: 426, ratio: 0.3544600938967136, speed: 1.3887796414237037\n",
      "Predicted Class: 1, Probabilities: [   0.043297     0.64672     0.30999]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 126, height: 423, ratio: 0.2978723404255319, speed: 6.432745006366154\n",
      "Predicted Class: 1, Probabilities: [   0.043297     0.64672     0.30999]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 131, height: 424, ratio: 0.3089622641509434, speed: 3.78189760396649\n",
      "Predicted Class: 1, Probabilities: [   0.043297     0.64672     0.30999]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 120, height: 421, ratio: 0.2850356294536817, speed: 4.655486332363052\n",
      "Predicted Class: 1, Probabilities: [   0.043297     0.64672     0.30999]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 141, height: 418, ratio: 0.3373205741626794, speed: 3.129867019315139\n",
      "Predicted Class: 1, Probabilities: [   0.043297     0.64672     0.30999]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 163, height: 414, ratio: 0.39371980676328505, speed: 3.7864137467742927\n",
      "Predicted Class: 1, Probabilities: [   0.043297     0.64672     0.30999]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 179, height: 418, ratio: 0.42822966507177035, speed: 6.58465539245372\n",
      "Predicted Class: 1, Probabilities: [   0.043297     0.64672     0.30999]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 193, height: 421, ratio: 0.4584323040380047, speed: 9.866666504894576\n",
      "Predicted Class: 1, Probabilities: [   0.043297     0.64672     0.30999]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 175, height: 425, ratio: 0.4117647058823529, speed: 7.057227781608338\n",
      "Predicted Class: 1, Probabilities: [   0.043297     0.64672     0.30999]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 171, height: 428, ratio: 0.39953271028037385, speed: 8.25714218972582\n",
      "Predicted Class: 1, Probabilities: [   0.043297     0.64672     0.30999]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 185, height: 447, ratio: 0.41387024608501116, speed: 2.4356099295803917\n",
      "Predicted Class: 1, Probabilities: [   0.043297     0.64672     0.30999]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 182, height: 448, ratio: 0.40625, speed: 0.676353147147576\n",
      "Predicted Class: 1, Probabilities: [   0.043297     0.64672     0.30999]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 193, height: 454, ratio: 0.4251101321585903, speed: 4.162228409123212\n",
      "Predicted Class: 1, Probabilities: [   0.043293      0.6467     0.31001]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 189, height: 467, ratio: 0.40471092077087795, speed: 9.556977588614501\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 190, height: 473, ratio: 0.40169133192389006, speed: 5.997856976544778\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 190, height: 480, ratio: 0.3958333333333333, speed: 6.709844929461483\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 191, height: 483, ratio: 0.39544513457556935, speed: 3.744467385999182\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 212, height: 483, ratio: 0.4389233954451346, speed: 0.651733931770606\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 224, height: 485, ratio: 0.4618556701030928, speed: 4.28282218517331\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 232, height: 487, ratio: 0.47638603696098564, speed: 2.950286539270011\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 237, height: 491, ratio: 0.48268839103869654, speed: 9.532426291066434\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 234, height: 506, ratio: 0.4624505928853755, speed: 16.84789778016534\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 243, height: 507, ratio: 0.47928994082840237, speed: 1.9014168135060756\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 263, height: 521, ratio: 0.5047984644913628, speed: 9.086468229803947\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 271, height: 537, ratio: 0.5046554934823091, speed: 10.54601948250746\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 277, height: 537, ratio: 0.515828677839851, speed: 2.7983119202882216\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 285, height: 520, ratio: 0.5480769230769231, speed: 6.991997137123482\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 287, height: 528, ratio: 0.5435606060606061, speed: 7.68470948604037\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 292, height: 531, ratio: 0.5499058380414312, speed: 4.042997686899386\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 294, height: 569, ratio: 0.5166959578207382, speed: 15.732383889779454\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 299, height: 539, ratio: 0.5547309833024119, speed: 6.613009548622363\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 298, height: 558, ratio: 0.5340501792114696, speed: 6.407295969242645\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 297, height: 554, ratio: 0.5361010830324909, speed: 1.7023961286816973\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 299, height: 559, ratio: 0.5348837209302325, speed: 2.84200919979793\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 299, height: 565, ratio: 0.5292035398230088, speed: 2.8065179845428694\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 302, height: 566, ratio: 0.5335689045936396, speed: 5.151873698232251\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 302, height: 570, ratio: 0.5298245614035088, speed: 5.82260464243538\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 302, height: 576, ratio: 0.5243055555555556, speed: 3.1566676697732095\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 302, height: 581, ratio: 0.5197934595524957, speed: 2.1144727215881285\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 302, height: 588, ratio: 0.5136054421768708, speed: 0.5237481239847646\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 301, height: 594, ratio: 0.5067340067340067, speed: 4.308583798748987\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 302, height: 593, ratio: 0.5092748735244519, speed: 2.8612289341218013\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 303, height: 593, ratio: 0.5109612141652614, speed: 0.4112180984673447\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 303, height: 596, ratio: 0.5083892617449665, speed: 3.082708562098607\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 302, height: 598, ratio: 0.5050167224080268, speed: 5.20285412700529\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 302, height: 600, ratio: 0.5033333333333333, speed: 0.80614580839566\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 302, height: 605, ratio: 0.4991735537190083, speed: 3.3316901840129542\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61578     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 304, height: 609, ratio: 0.49917898193760263, speed: 1.7943080541095475\n",
      "Predicted Class: 1, Probabilities: [   0.038678     0.61577     0.34555]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 305, height: 615, ratio: 0.4959349593495935, speed: 2.488081219478741\n",
      "Predicted Class: 1, Probabilities: [   0.038685     0.61561     0.34571]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 309, height: 615, ratio: 0.5024390243902439, speed: 1.6804643726102482\n",
      "Predicted Class: 1, Probabilities: [   0.039216     0.60487     0.35591]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 310, height: 613, ratio: 0.5057096247960848, speed: 1.4780587351866865\n",
      "Predicted Class: 1, Probabilities: [   0.038813     0.61267     0.34852]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 310, height: 613, ratio: 0.5057096247960848, speed: 0.9915169143501991\n",
      "Predicted Class: 1, Probabilities: [     0.0392     0.60516     0.35564]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 310, height: 614, ratio: 0.504885993485342, speed: 0.750798005017588\n",
      "Predicted Class: 1, Probabilities: [   0.041965     0.56352     0.39452]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 308, height: 617, ratio: 0.4991896272285251, speed: 0.6837964142714104\n",
      "Predicted Class: 1, Probabilities: [   0.043182     0.54691     0.40991]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 308, height: 622, ratio: 0.49517684887459806, speed: 0.30734764156481753\n",
      "Predicted Class: 1, Probabilities: [   0.043235     0.54619     0.41058]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 309, height: 623, ratio: 0.4959871589085072, speed: 3.487404573777869\n",
      "Predicted Class: 1, Probabilities: [   0.043235     0.54618     0.41058]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 309, height: 624, ratio: 0.4951923076923077, speed: 3.8170244221601264\n",
      "Predicted Class: 1, Probabilities: [   0.043235     0.54618     0.41058]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 310, height: 628, ratio: 0.49363057324840764, speed: 3.8659320421312406\n",
      "Predicted Class: 1, Probabilities: [   0.043236     0.54618     0.41058]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 311, height: 628, ratio: 0.49522292993630573, speed: 3.80153881531514\n",
      "Predicted Class: 1, Probabilities: [   0.043245     0.54636     0.41039]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 311, height: 635, ratio: 0.48976377952755906, speed: 1.9108565945603542\n",
      "Predicted Class: 1, Probabilities: [   0.050837     0.61809     0.33107]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 311, height: 641, ratio: 0.48517940717628705, speed: 1.458174541562465\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 311, height: 645, ratio: 0.4821705426356589, speed: 1.4882969642530823\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 313, height: 647, ratio: 0.48377125193199383, speed: 0.844496329478752\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 313, height: 653, ratio: 0.4793261868300153, speed: 0.7333310216672929\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 314, height: 653, ratio: 0.48085758039816234, speed: 3.929389982930985\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 314, height: 653, ratio: 0.48085758039816234, speed: 4.722963079700281\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 316, height: 652, ratio: 0.48466257668711654, speed: 1.472526294471755\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 316, height: 655, ratio: 0.48244274809160304, speed: 1.386422706047397\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 313, height: 661, ratio: 0.4735249621785174, speed: 0.252977072581692\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 312, height: 661, ratio: 0.4720121028744327, speed: 1.638850019566335\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 312, height: 660, ratio: 0.4727272727272727, speed: 1.067567399854274\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 313, height: 662, ratio: 0.472809667673716, speed: 1.5650910699121272\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 313, height: 664, ratio: 0.4713855421686747, speed: 1.7316866309608367\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 314, height: 665, ratio: 0.47218045112781953, speed: 1.6060893296957666\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 313, height: 666, ratio: 0.46996996996997, speed: 0.6665550938710815\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 313, height: 669, ratio: 0.4678624813153961, speed: 0.9180061266940658\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 312, height: 671, ratio: 0.46497764530551416, speed: 0.4585394634925136\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 312, height: 670, ratio: 0.46567164179104475, speed: 0.7234458412062801\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 313, height: 669, ratio: 0.4678624813153961, speed: 0.5102536604576486\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 314, height: 669, ratio: 0.4693572496263079, speed: 1.5773531352902643\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 313, height: 671, ratio: 0.46646795827123694, speed: 0.9398434123667119\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 314, height: 672, ratio: 0.46726190476190477, speed: 0.7065488795730119\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 314, height: 672, ratio: 0.46726190476190477, speed: 1.057817901549565\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 313, height: 672, ratio: 0.46577380952380953, speed: 0.7825470629829239\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 313, height: 672, ratio: 0.46577380952380953, speed: 1.02030795766413\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 313, height: 673, ratio: 0.4650817236255572, speed: 1.0007118058588746\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 313, height: 673, ratio: 0.4650817236255572, speed: 0.984845909317459\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 310, height: 673, ratio: 0.4606240713224368, speed: 1.0067605617145914\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 309, height: 676, ratio: 0.45710059171597633, speed: 1.055286911263816\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 309, height: 676, ratio: 0.45710059171597633, speed: 0.6980740566946624\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 311, height: 676, ratio: 0.46005917159763315, speed: 1.215280640813632\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 308, height: 678, ratio: 0.45427728613569324, speed: 1.2868167207418268\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 309, height: 678, ratio: 0.4557522123893805, speed: 1.0530754195083523\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 310, height: 678, ratio: 0.45722713864306785, speed: 1.0147444511091825\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 308, height: 678, ratio: 0.45427728613569324, speed: 0.7969762061776463\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 307, height: 680, ratio: 0.4514705882352941, speed: 1.0162510762631616\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 308, height: 681, ratio: 0.4522760646108664, speed: 0.5057744821174318\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 308, height: 680, ratio: 0.45294117647058824, speed: 0.7542483736065709\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 308, height: 680, ratio: 0.45294117647058824, speed: 1.2304696380915168\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 309, height: 679, ratio: 0.45508100147275404, speed: 1.1138830868252885\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 306, height: 681, ratio: 0.44933920704845814, speed: 1.4012172206080762\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 304, height: 681, ratio: 0.44640234948604995, speed: 1.6956467780663371\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 303, height: 681, ratio: 0.44493392070484583, speed: 0.790207691653411\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 303, height: 681, ratio: 0.44493392070484583, speed: 0.2034605095566983\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 305, height: 680, ratio: 0.4485294117647059, speed: 0.5156536149936571\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 306, height: 680, ratio: 0.45, speed: 0.5602659915816348\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 307, height: 680, ratio: 0.4514705882352941, speed: 0.34002386562126513\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 307, height: 680, ratio: 0.4514705882352941, speed: 0.6371243433522438\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 306, height: 680, ratio: 0.45, speed: 0.8113359098286177\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 305, height: 680, ratio: 0.4485294117647059, speed: 0.241657070376682\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 304, height: 680, ratio: 0.4470588235294118, speed: 1.212059672066743\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 303, height: 680, ratio: 0.4455882352941177, speed: 1.025096146690583\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 302, height: 680, ratio: 0.4441176470588235, speed: 0.36054423758214194\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 302, height: 680, ratio: 0.4441176470588235, speed: 0.1732970607420287\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 302, height: 680, ratio: 0.4441176470588235, speed: 0.4731538535359068\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 301, height: 680, ratio: 0.4426470588235294, speed: 0.2066901461348489\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 300, height: 679, ratio: 0.4418262150220913, speed: 0.43204539564731037\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 299, height: 678, ratio: 0.4410029498525074, speed: 0.9301241834513433\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 298, height: 676, ratio: 0.4408284023668639, speed: 0.32504752383770047\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 298, height: 673, ratio: 0.4427934621099554, speed: 0.5023315038251006\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 299, height: 671, ratio: 0.4456035767511177, speed: 0.7721441731721105\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 299, height: 670, ratio: 0.4462686567164179, speed: 0.5947039962092346\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 299, height: 670, ratio: 0.4462686567164179, speed: 1.3338491245504203\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 299, height: 668, ratio: 0.4476047904191617, speed: 1.5599959308805849\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 298, height: 668, ratio: 0.44610778443113774, speed: 1.934122613242405\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 298, height: 667, ratio: 0.44677661169415295, speed: 0.47279254340720617\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 297, height: 666, ratio: 0.44594594594594594, speed: 1.7894289675377848\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 296, height: 665, ratio: 0.44511278195488724, speed: 1.0045391554798113\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 297, height: 664, ratio: 0.44728915662650603, speed: 1.1765067104274605\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 299, height: 662, ratio: 0.4516616314199396, speed: 0.9687979457950829\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 299, height: 660, ratio: 0.453030303030303, speed: 0.5567039791519826\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 299, height: 659, ratio: 0.4537177541729894, speed: 0.4162694952102907\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 299, height: 658, ratio: 0.45440729483282677, speed: 1.1180982259205734\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 301, height: 657, ratio: 0.4581430745814307, speed: 0.12505615092712297\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 301, height: 657, ratio: 0.4581430745814307, speed: 0.48954142644202836\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 301, height: 656, ratio: 0.45884146341463417, speed: 0.3299993548578376\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 302, height: 655, ratio: 0.46106870229007635, speed: 0.6167152771554191\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 302, height: 655, ratio: 0.46106870229007635, speed: 1.148393287254897\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 306, height: 655, ratio: 0.467175572519084, speed: 0.577352117376918\n",
      "Predicted Class: 1, Probabilities: [   0.050843     0.61812     0.33104]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 306, height: 655, ratio: 0.467175572519084, speed: 1.0551173704654844\n",
      "Predicted Class: 1, Probabilities: [   0.050849     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 310, height: 655, ratio: 0.4732824427480916, speed: 1.2539372012969834\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 311, height: 655, ratio: 0.47480916030534354, speed: 1.689437071414031\n",
      "Predicted Class: 1, Probabilities: [    0.05085     0.61815       0.331]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 315, height: 653, ratio: 0.48238897396630936, speed: 0.5567180261319364\n",
      "Predicted Class: 1, Probabilities: [   0.050839      0.6181     0.33106]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 317, height: 653, ratio: 0.48545176110260335, speed: 0.9276074499446463\n",
      "Predicted Class: 1, Probabilities: [   0.050793     0.61789     0.33131]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 320, height: 653, ratio: 0.4900459418070444, speed: 0.7738637728990233\n",
      "Predicted Class: 1, Probabilities: [   0.050388     0.61601      0.3336]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 320, height: 654, ratio: 0.4892966360856269, speed: 0.6535114288914873\n",
      "Predicted Class: 1, Probabilities: [   0.050611     0.61706     0.33233]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 323, height: 653, ratio: 0.4946401225114854, speed: 1.913950012029187\n",
      "Predicted Class: 1, Probabilities: [   0.050349     0.61582     0.33383]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 325, height: 650, ratio: 0.5, speed: 1.0026765944195721\n",
      "Predicted Class: 1, Probabilities: [   0.045607     0.58091     0.37348]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 328, height: 649, ratio: 0.5053929121725732, speed: 0.7747875837938095\n",
      "Predicted Class: 1, Probabilities: [   0.043298     0.54737     0.40933]\n",
      "Processed landmarks length: 22\n",
      "BBox width: 331, height: 645, ratio: 0.5131782945736434, speed: 0.4706430677039\n",
      "Predicted Class: 1, Probabilities: [   0.043235     0.54618     0.41058]\n"
     ]
    }
   ],
   "source": [
    "# 바운딩 박스 계산 및 그리기 함수\n",
    "def calculate_and_draw_bbox(frame, landmarks):\n",
    "    x_coordinates = landmarks[:, 0]\n",
    "    y_coordinates = landmarks[:, 1]\n",
    "    \n",
    "    x1 = max(0, int(np.min(x_coordinates)))\n",
    "    y1 = max(0, int(np.min(y_coordinates)))\n",
    "    x2 = min(frame.shape[1], int(np.max(x_coordinates)))\n",
    "    y2 = min(frame.shape[0], int(np.max(y_coordinates)))\n",
    "    \n",
    "    bbox_width = x2 - x1\n",
    "    bbox_height = y2 - y1\n",
    "    \n",
    "    # 높이가 0일 경우 비율을 무한대로 설정\n",
    "    bbox_ratio = bbox_width / bbox_height if bbox_height != 0 else float('inf')\n",
    "    \n",
    "    # 바운딩 박스 클래스 결정\n",
    "    bbox_class = 0\n",
    "    if bbox_ratio < 0.5:\n",
    "        bbox_class = 0  # Normal\n",
    "    elif 0.5 <= bbox_ratio < 0.7:\n",
    "        bbox_class = 2  # Danger\n",
    "    else:\n",
    "        bbox_class = 1  # Fall\n",
    "    \n",
    "    # 바운딩 박스를 조금 더 넓게 조정 (각 방향으로 50픽셀 추가)\n",
    "    padding = 50\n",
    "    x1 = max(0, x1 - padding)\n",
    "    y1 = max(0, y1 - padding)\n",
    "    x2 = min(frame.shape[1], x2 + padding)\n",
    "    y2 = min(frame.shape[0], y2 + padding)\n",
    "    \n",
    "    return (x1, y1, x2, y2), bbox_width, bbox_height, bbox_ratio, bbox_class\n",
    "\n",
    "def calculate_head_upper_body_speed(keypoints, prev_keypoints):\n",
    "    h = np.array([keypoints[0, 0], keypoints[0, 1]])  # 머리 좌표\n",
    "    l = np.array([keypoints[11, 0], keypoints[11, 1]])  # 왼쪽 어깨 좌표\n",
    "    r = np.array([keypoints[12, 0], keypoints[12, 1]])  # 오른쪽 어깨 좌표\n",
    "\n",
    "    # 이전 프레임의 좌표\n",
    "    prev_h = np.array([prev_keypoints[0, 0], prev_keypoints[0, 1]])\n",
    "    prev_l = np.array([prev_keypoints[11, 0], prev_keypoints[11, 1]])\n",
    "    prev_r = np.array([prev_keypoints[12, 0], prev_keypoints[12, 1]])\n",
    "\n",
    "    # 현재 프레임과 이전 프레임의 상체 중심\n",
    "    center_new = (h + l + r) / 3\n",
    "    center_prev = (prev_h + prev_l + prev_r) / 3\n",
    "\n",
    "    # 유클리드 거리 계산 (속도)\n",
    "    speed = distance.euclidean(center_new, center_prev)\n",
    "    return speed\n",
    "\n",
    "# MediaPipe 초기화\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "LANDMARKS = [0, 11, 12, 15, 16, 23, 24, 25, 26, 27, 28]\n",
    "\n",
    "def process_landmarks(landmarks): \n",
    "    selected_landmarks = landmarks[LANDMARKS]\n",
    "    return selected_landmarks[:, :2].flatten()\n",
    "\n",
    "# GRU 모델 정의\n",
    "class GRUModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2, output_size=3, dropout=0.5):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# GRU 모델 로드\n",
    "input_size = 27  \n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "output_size = 3\n",
    "dropout = 0.5    \n",
    "\n",
    "gru_model = GRUModel(input_size, hidden_size, num_layers, output_size, dropout)\n",
    "gru_model.load_state_dict(torch.load('D:\\\\project\\\\prjvenv\\\\GRU\\\\best_GRU_model.pt', map_location=torch.device('cpu')))\n",
    "gru_model.eval()\n",
    "\n",
    "# 클래스 이름 정의\n",
    "class_names = {0: 'Normal', 1: 'Fall', 2: 'Danger'}\n",
    "\n",
    "# 낙상 감지 함수\n",
    "def detect_fall(landmarks, prev_landmarks, frame):\n",
    "    speed = calculate_head_upper_body_speed(landmarks, prev_landmarks) if prev_landmarks is not None else 0\n",
    "    processed_landmarks = process_landmarks(landmarks)\n",
    "    \n",
    "    bbox_info = calculate_and_draw_bbox(frame, landmarks)\n",
    "    \n",
    "    if bbox_info is None:\n",
    "        return None\n",
    "    \n",
    "    bbox_width, bbox_height, bbox_ratio, bbox_class = bbox_info[1:4] + (bbox_info[4],)\n",
    "    \n",
    "    print(f\"Processed landmarks length: {len(processed_landmarks)}\")\n",
    "    print(f\"BBox width: {bbox_width}, height: {bbox_height}, ratio: {bbox_ratio}, speed: {speed}\")   \n",
    "\n",
    "    # processed_landmarks와 함께 바운딩 박스 좌표 및 속도 정보 추가\n",
    "    input_data = np.concatenate([processed_landmarks,\n",
    "                                  [bbox_width,\n",
    "                                   bbox_height,\n",
    "                                   bbox_ratio,\n",
    "                                   speed,\n",
    "                                   bbox_class]])\n",
    "    \n",
    "    if len(input_data) != input_size:\n",
    "        print(f\"Warning: input_data length is {len(input_data)}, expected {input_size}\")\n",
    "        return None\n",
    "    \n",
    "    input_tensor = torch.FloatTensor(input_data).unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = gru_model(input_tensor)\n",
    "\n",
    "    probabilities = torch.softmax(output, dim=1).numpy()[0]\n",
    "    predicted_class = torch.argmax(output).item()\n",
    "    \n",
    "    return predicted_class, probabilities\n",
    "\n",
    "# 비디오 파일 경로 지정\n",
    "video_path = \"D:\\\\human_fall\\\\re_video\\\\validation\\\\N\\\\02327_H_A_N_C6.mp4\"\n",
    "# 비디오 파일 열기\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# 비디오 속성 가져오기\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# 출력 비디오 설정\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out_path='data_video_test_outputY_GRU_only.mp4'\n",
    "out= cv2.VideoWriter(out_path,fourcc,fps,(width,height))\n",
    "\n",
    "prev_landmarks=None\n",
    "\n",
    "# 프레임 처리 루프\n",
    "while cap.isOpened():\n",
    "    ret , frame= cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # MediaPipe로 포즈 추정 \n",
    "    rgb_frame=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results_pose=pose.process(rgb_frame)\n",
    "\n",
    "    if results_pose.pose_landmarks:\n",
    "       landmarks=np.array([[lm.x * width , lm.y * height , lm.z] for lm in results_pose.pose_landmarks.landmark])\n",
    "       \n",
    "       # 바운딩 박스 계산 및 그리기 \n",
    "       bbox_info=calculate_and_draw_bbox(frame , landmarks)\n",
    "\n",
    "       if prev_landmarks is not None: \n",
    "           label , probs=detect_fall(landmarks , prev_landmarks , frame)\n",
    "           print(f\"Predicted Class: {label}, Probabilities: {probs}\")  \n",
    "       else: \n",
    "           label=None \n",
    "\n",
    "       prev_landmarks=landmarks \n",
    "\n",
    "       # 바운딩 박스와 라벨 그리기 \n",
    "       x1 , y1 , x2 , y2=bbox_info[0]   \n",
    "       color=(0 ,255 ,0) if label==0 else ((0, 255, 255) if label==1 else (255, 0, 0)) \n",
    "       cv2.rectangle(frame , (x1 , y1) , (x2 , y2) , color ,2)\n",
    "       # 클래스 이름을 사용하여 텍스트 표시\n",
    "       class_name = class_names[label] if label is not None else 'Unknown'\n",
    "       cv2.putText(frame , f'GRU: {label}' , (x1 , y1 -10) , cv2.FONT_HERSHEY_SIMPLEX ,0.7 , color ,2)\n",
    "\n",
    "       # 랜드마크 표시 \n",
    "       mp_drawing.draw_landmarks(frame , results_pose.pose_landmarks , mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    # 프레임 저장 및 출력 \n",
    "    resized_frame=cv2.resize(frame,(1920 ,1080))  \n",
    "    out.write(resized_frame) \n",
    "    cv2.imshow('Fall Detection' , resized_frame) \n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "       break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU 모델만 사용\n",
    "* 속도를 우선적으로 클래스 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 2\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 2\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 2\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 2\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 2\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 2\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 0\n",
      "Predicted Class: 1\n",
      "Predicted Class: 0\n",
      "Predicted Class: 1\n",
      "Predicted Class: 0\n",
      "Predicted Class: 2\n",
      "Predicted Class: 0\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 2\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 2\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 2\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 2\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n"
     ]
    }
   ],
   "source": [
    "# MediaPipe 초기화\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 랜드마크 인덱스 정의 (예: 코, 왼쪽 어깨, 오른쪽 어깨 등)\n",
    "LANDMARKS = [0, 11, 12, 15, 16, 23, 24, 25, 26, 27, 28]  # 총 11개 랜드마크\n",
    "\n",
    "# GRU 모델 정의\n",
    "class GRUModel(torch.nn.Module):\n",
    "    def __init__(self, input_size=27):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size = 64\n",
    "        self.num_layers = num_layers = 2\n",
    "        self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True,\n",
    "                          dropout=0.5)\n",
    "        self.fc = nn.Linear(hidden_size, 3)  # output_size를 직접 지정합니다.\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# GRU 모델 로드\n",
    "input_size = 27\n",
    "gru_model = GRUModel(input_size=input_size)  \n",
    "gru_model.load_state_dict(torch.load('D:\\\\project\\\\prjvenv\\\\GRU\\\\best_GRU_model_2.pt', map_location=torch.device('cpu')))\n",
    "gru_model.eval()\n",
    "\n",
    "# 클래스 이름 정의\n",
    "class_names = {0: 'Normal', 1: 'Fall', 2: 'Danger'}\n",
    "\n",
    "# Threshold 값 정의\n",
    "threshold_normal = 6.5   # 일반 상태로 간주되는 속도 임계값\n",
    "threshold_danger = 10.5   # 위험 상태로 간주되는 속도 임계값\n",
    "\n",
    "def calculate_head_upper_body_speed(keypoints, prev_keypoints):\n",
    "    h = np.array([keypoints[0, 0], keypoints[0, 1]])   # 머리 좌표\n",
    "    l = np.array([keypoints[11, 0], keypoints[11, 1]])  # 왼쪽 어깨 좌표\n",
    "    r = np.array([keypoints[12, 0], keypoints[12, 1]])  # 오른쪽 어깨 좌표\n",
    "\n",
    "    # 이전 프레임의 좌표가 없는 경우 속도는 0으로 설정\n",
    "    if prev_keypoints is None:\n",
    "        return 0.0\n",
    "\n",
    "    prev_h = np.array([prev_keypoints[0, 0], prev_keypoints[0, 1]])\n",
    "    prev_l = np.array([prev_keypoints[11, 0], prev_keypoints[11, 1]])\n",
    "    prev_r = np.array([prev_keypoints[12, 0], prev_keypoints[12, 1]])\n",
    "\n",
    "    # 현재 프레임과 이전 프레임의 상체 중심 계산\n",
    "    center_new = (h + l + r) / 3\n",
    "    center_prev = (prev_h + prev_l + prev_r) / 3\n",
    "\n",
    "    # 유클리드 거리 계산 (속도)\n",
    "    speed = distance.euclidean(center_new, center_prev)\n",
    "    return speed\n",
    "\n",
    "def process_landmarks(landmarks): \n",
    "    selected_landmarks = landmarks[LANDMARKS]   # 지정된 랜드마크 선택 \n",
    "    return selected_landmarks[:, :2].flatten()   # (x,y) 좌표 반환\n",
    "\n",
    "def calculate_and_draw_bbox(frame, landmarks):\n",
    "    x_coordinates = landmarks[:, 0]\n",
    "    y_coordinates = landmarks[:, 1]\n",
    "    \n",
    "    x1 = max(0, int(np.min(x_coordinates)))\n",
    "    y1 = max(0, int(np.min(y_coordinates)))\n",
    "    x2 = min(frame.shape[1], int(np.max(x_coordinates)))\n",
    "    y2 = min(frame.shape[0], int(np.max(y_coordinates)))\n",
    "    \n",
    "    bbox_width = x2 - x1\n",
    "    bbox_height = y2 - y1\n",
    "    \n",
    "    # 높이가 0일 경우 비율을 무한대로 설정\n",
    "    bbox_ratio = bbox_width / bbox_height if bbox_height != 0 else float('inf')\n",
    "    \n",
    "    # 바운딩 박스를 조금 더 넓게 조정 (각 방향으로 패딩 추가)\n",
    "    padding = 50\n",
    "    x1 = max(0, x1 - padding)\n",
    "    y1 = max(0, y1 - padding)\n",
    "    x2 = min(frame.shape[1], x2 + padding)\n",
    "    y2 = min(frame.shape[0], y2 + padding)\n",
    "\n",
    "    return (x1, y1), (x2, y2), bbox_width, bbox_height\n",
    "\n",
    "# 낙상 감지 함수\n",
    "def detect_fall(landmarks, prev_landmarks):\n",
    "    speed = calculate_head_upper_body_speed(landmarks, prev_landmarks)\n",
    "    \n",
    "    processed_landmarks = process_landmarks(landmarks)\n",
    "\n",
    "    # 바운딩 박스 계산 및 그리기 \n",
    "    top_left_bbox , bottom_right_bbox , bbox_width , bbox_height= calculate_and_draw_bbox(frame , landmarks)\n",
    "\n",
    "    \n",
    "    # 속도 기반 클래스 결정\n",
    "    if speed < threshold_normal:\n",
    "        bbox_class = 0   # Normal \n",
    "    elif speed < threshold_danger:\n",
    "        bbox_class = 2   # Danger \n",
    "    else:\n",
    "        bbox_class = 1   # Fall \n",
    "\n",
    "    return bbox_class\n",
    "\n",
    "# 비디오 파일 경로 지정 및 열기 \n",
    "video_path=\"D:\\\\human_fall\\\\re_video\\\\validation\\\\Y\\\\00170_H_A_SY_C5.mp4\"\n",
    "cap=cv2.VideoCapture(video_path)\n",
    "\n",
    "# 비디오 속성 가져오기 \n",
    "width=int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height=int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps=cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# 출력 비디오 설정 \n",
    "fourcc=cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out_path='video_test_GRU_onlyspeed_8.mp4'\n",
    "out=cv2.VideoWriter(out_path,fourcc,fps,(width,height))\n",
    "\n",
    "prev_landmarks=None\n",
    "\n",
    "# 프레임 처리 루프 \n",
    "while cap.isOpened():\n",
    "    ret , frame=cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb_frame=cv2.cvtColor(frame , cv2.COLOR_BGR2RGB)\n",
    "    results_pose=pose.process(rgb_frame)\n",
    "\n",
    "    if results_pose.pose_landmarks:\n",
    "        landmarks=np.array([[lm.x * width , lm.y * height , lm.z] for lm in results_pose.pose_landmarks.landmark])\n",
    "       \n",
    "        if prev_landmarks is not None: \n",
    "            label=detect_fall(landmarks , prev_landmarks)  \n",
    "            print(f\"Predicted Class: {label}\")  \n",
    "        else: \n",
    "            label=None \n",
    "\n",
    "        prev_landmarks=landmarks \n",
    "\n",
    "        # 바운딩 박스와 라벨 그리기 \n",
    "        top_left_bbox , bottom_right_bbox , _, _= calculate_and_draw_bbox(frame , landmarks)  \n",
    "        color=(0 ,255 ,0) if label==0 else ((0 ,255, 255) if label==2 else (0, 0, 255)) \n",
    "        cv2.rectangle(frame , top_left_bbox , bottom_right_bbox , color ,2)\n",
    "        class_name=class_names[label] if label is not None else 'Unknown'\n",
    "        cv2.putText(frame , f'GRU: {class_name}' , (top_left_bbox[0] , top_left_bbox[1] -10) , cv2.FONT_HERSHEY_SIMPLEX ,0.7 , color ,2)\n",
    "\n",
    "        # 랜드마크 표시 \n",
    "        mp_drawing.draw_landmarks(frame , results_pose.pose_landmarks , mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    # 프레임 저장 및 출력 \n",
    "    resized_frame=cv2.resize(frame,(1920 ,1080))  \n",
    "    out.write(frame) \n",
    "    cv2.imshow('Fall Detection' , resized_frame) \n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "         break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU 모델만 사용\n",
    "* 속도 기반으로 초기 클래스 결정 후 bbox의 비율로 클래스 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 0\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 2\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 0\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 1\n",
      "Predicted Class: 2\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 2\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n"
     ]
    }
   ],
   "source": [
    "# MediaPipe 초기화\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 랜드마크 인덱스 정의 (예: 코, 왼쪽 어깨, 오른쪽 어깨 등)\n",
    "LANDMARKS = [0, 11, 12, 15, 16, 23, 24, 25, 26, 27, 28]  # 총 11개 랜드마크\n",
    "\n",
    "# GRU 모델 정의\n",
    "class GRUModel(torch.nn.Module):\n",
    "    def __init__(self, input_size=27):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size = 64\n",
    "        self.num_layers = num_layers = 2\n",
    "        self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True,\n",
    "                          dropout=0.5)\n",
    "        self.fc = nn.Linear(hidden_size, 3)  # output_size를 직접 지정합니다.\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# GRU 모델 로드\n",
    "input_size = 27\n",
    "gru_model = GRUModel(input_size=input_size)  \n",
    "gru_model.load_state_dict(torch.load('D:\\\\project\\\\prjvenv\\\\GRU\\\\best_GRU_model_2.pt', map_location=torch.device('cpu')))\n",
    "gru_model.eval()\n",
    "\n",
    "# 클래스 이름 정의\n",
    "class_names = {0: 'Normal', 1: 'Fall', 2: 'Danger'}\n",
    "\n",
    "# Threshold 값 정의\n",
    "threshold_normal = 6.5   # 일반 상태로 간주되는 속도 임계값\n",
    "threshold_danger = 10.5   # 위험 상태로 간주되는 속도 임계값\n",
    "\n",
    "def calculate_head_upper_body_speed(keypoints, prev_keypoints):\n",
    "    h = np.array([keypoints[0, 0], keypoints[0, 1]])   # 머리 좌표\n",
    "    l = np.array([keypoints[11, 0], keypoints[11, 1]])  # 왼쪽 어깨 좌표\n",
    "    r = np.array([keypoints[12, 0], keypoints[12, 1]])  # 오른쪽 어깨 좌표\n",
    "\n",
    "    # 이전 프레임의 좌표가 없는 경우 속도는 0으로 설정\n",
    "    if prev_keypoints is None:\n",
    "        return 0.0\n",
    "\n",
    "    prev_h = np.array([prev_keypoints[0, 0], prev_keypoints[0, 1]])\n",
    "    prev_l = np.array([prev_keypoints[11, 0], prev_keypoints[11, 1]])\n",
    "    prev_r = np.array([prev_keypoints[12, 0], prev_keypoints[12, 1]])\n",
    "\n",
    "    # 현재 프레임과 이전 프레임의 상체 중심 계산\n",
    "    center_new = (h + l + r) / 3\n",
    "    center_prev = (prev_h + prev_l + prev_r) / 3\n",
    "\n",
    "    # 유클리드 거리 계산 (속도)\n",
    "    speed = distance.euclidean(center_new, center_prev)\n",
    "    return speed\n",
    "\n",
    "def process_landmarks(landmarks): \n",
    "    selected_landmarks = landmarks[LANDMARKS]   # 지정된 랜드마크 선택 \n",
    "    return selected_landmarks[:, :2].flatten()   # (x,y) 좌표 반환\n",
    "\n",
    "def calculate_and_draw_bbox(frame, landmarks):\n",
    "    x_coordinates = landmarks[:, 0]\n",
    "    y_coordinates = landmarks[:, 1]\n",
    "    \n",
    "    x1 = max(0, int(np.min(x_coordinates)))\n",
    "    y1 = max(0, int(np.min(y_coordinates)))\n",
    "    x2 = min(frame.shape[1], int(np.max(x_coordinates)))\n",
    "    y2 = min(frame.shape[0], int(np.max(y_coordinates)))\n",
    "    \n",
    "    bbox_width = x2 - x1\n",
    "    bbox_height = y2 - y1\n",
    "    \n",
    "    # 높이가 0일 경우 비율을 무한대로 설정\n",
    "    bbox_ratio = bbox_width / bbox_height if bbox_height != 0 else float('inf')\n",
    "    \n",
    "    # 바운딩 박스를 조금 더 넓게 조정 (각 방향으로 패딩 추가)\n",
    "    padding = 50\n",
    "    x1 = max(0, x1 - padding)\n",
    "    y1 = max(0, y1 - padding)\n",
    "    x2 = min(frame.shape[1], x2 + padding)\n",
    "    y2 = min(frame.shape[0], y2 + padding)\n",
    "\n",
    "    return (x1, y1), (x2, y2), bbox_width, bbox_height\n",
    "\n",
    "# 낙상 감지 함수\n",
    "def detect_fall(landmarks, prev_landmarks, fall_frame_counter): # 일정 프레임 이상 fall 클래스가 지속되면 fall 클래스 고정\n",
    "    global determine_fall\n",
    "    \n",
    "    if determine_fall : \n",
    "        return 1, fall_frame_counter\n",
    "    \n",
    "    speed = calculate_head_upper_body_speed(landmarks, prev_landmarks)\n",
    "    \n",
    "    processed_landmarks = process_landmarks(landmarks)\n",
    "\n",
    "    # 바운딩 박스 계산 및 그리기 \n",
    "    top_left_bbox , bottom_right_bbox , bbox_width , bbox_height= calculate_and_draw_bbox(frame , landmarks)\n",
    "    \n",
    "    # 바운딩 박스 비율 계산\n",
    "    bbox_ratio = bbox_width / bbox_height if bbox_height != 0 else float('inf')\n",
    "\n",
    "    \n",
    "    # 속도 기반 클래스 결정\n",
    "    if speed < threshold_normal:\n",
    "        bbox_class = 0   # Normal \n",
    "    elif speed < threshold_danger:\n",
    "        bbox_class = 2   # Danger \n",
    "    else:\n",
    "        bbox_class = 1   # Fall \n",
    "    \n",
    "    # 바운딩 박스 비율에 따른 클래스 조정\n",
    "    if bbox_class == 0 and bbox_ratio < 0.5 :\n",
    "        bbox_class = 0   # Normal에서 Normal로 조정\n",
    "    elif bbox_class == 0 and 0.5 <= bbox_ratio <= 0.7 : \n",
    "        bbox_class = 2   # Normal에서 Danger로 조정\n",
    "    elif bbox_class == 0 and bbox_ratio > 1 : \n",
    "        bbox_class = 1   # Normal에서 Fall로 조정\n",
    "        \n",
    "    elif bbox_class == 2 and bbox_ratio < 0.5 : \n",
    "        bbox_class = 0\n",
    "    elif bbox_class == 2 and 0.5 <= bbox_ratio <= 0.7 : \n",
    "        bbox_class = 2\n",
    "    elif bbox_class == 2 and bbox_ratio > 1 : \n",
    "        bbox_class = 1\n",
    "        \n",
    "    elif bbox_class == 1 and bbox_ratio < 0.5 : \n",
    "        bbox_class = 0\n",
    "    elif bbox_class == 1 and 0.5 <= bbox_ratio <= 0.7 : \n",
    "        bbox_class = 2\n",
    "    elif bbox_class == 1 and bbox_ratio > 1 : \n",
    "        bbox_class = 1\n",
    "        \n",
    "    # Fall_counter 업데이트\n",
    "    if bbox_class == 1 : \n",
    "        fall_frame_counter += 1\n",
    "        if fall_frame_counter >= 10 : \n",
    "            determine_fall = True\n",
    "    \n",
    "    else : \n",
    "        fall_frame_counter = 0\n",
    "\n",
    "    return bbox_class, fall_frame_counter\n",
    "\n",
    "# 비디오 파일 경로 지정 및 열기 \n",
    "video_path = \"D:\\\\human_fall\\\\re_video\\\\validation\\\\Y\\\\02968_L_F_FY_C4.mp4\"\n",
    "cap=cv2.VideoCapture(video_path)\n",
    "\n",
    "# 비디오 속성 가져오기 \n",
    "width=int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height=int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps=cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# 출력 비디오 설정 \n",
    "fourcc=cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out_path='GRU_speed+bboxratio_Y_8.mp4'\n",
    "out=cv2.VideoWriter(out_path,fourcc,fps,(width,height))\n",
    "\n",
    "prev_landmarks=None\n",
    "\n",
    "# 프레임 처리 루프 \n",
    "fall_frame_counter = 0\n",
    "fall_threshold = 10\n",
    "determine_fall = False\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret , frame=cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb_frame=cv2.cvtColor(frame , cv2.COLOR_BGR2RGB)\n",
    "    results_pose=pose.process(rgb_frame)\n",
    "\n",
    "    if results_pose.pose_landmarks:\n",
    "        landmarks=np.array([[lm.x * width , lm.y * height , lm.z] for lm in results_pose.pose_landmarks.landmark])\n",
    "       \n",
    "        if prev_landmarks is not None: \n",
    "            label, fall_frame_counter =detect_fall(landmarks , prev_landmarks, fall_frame_counter)  \n",
    "            print(f\"Predicted Class: {label}\")  \n",
    "        else: \n",
    "            label=None \n",
    "\n",
    "        prev_landmarks=landmarks \n",
    "\n",
    "        # 바운딩 박스와 라벨 그리기 \n",
    "        top_left_bbox , bottom_right_bbox , _, _= calculate_and_draw_bbox(frame , landmarks)  \n",
    "        color=(0 ,255 ,0) if label==0 else ((0 ,255, 255) if label==2 else (0, 0, 255)) \n",
    "        cv2.rectangle(frame , top_left_bbox , bottom_right_bbox , color ,2)\n",
    "        class_name=class_names[label] if label is not None else 'Unknown'\n",
    "        cv2.putText(frame , f'GRU: {class_name}' , (top_left_bbox[0] , top_left_bbox[1] -10) , cv2.FONT_HERSHEY_SIMPLEX ,0.7 , color ,2)\n",
    "\n",
    "        if determine_fall : \n",
    "            cv2.putText(frame, 'FALL', (10, 30), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 0, 255), 3)\n",
    "        # 랜드마크 표시 \n",
    "        mp_drawing.draw_landmarks(frame , results_pose.pose_landmarks , mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    # 프레임 저장 및 출력 \n",
    "    resized_frame=cv2.resize(frame,(1920 ,1080))  \n",
    "    out.write(frame) \n",
    "    cv2.imshow('Fall Detection' , resized_frame) \n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'):\n",
    "         break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 Fall, 74.9ms\n",
      "Speed: 2.0ms preprocess, 74.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 2.0ms\n",
      "Speed: 2.0ms preprocess, 2.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 5.0ms\n",
      "Speed: 3.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 10.0ms\n",
      "Speed: 4.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 12.0ms\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 12.0ms\n",
      "Speed: 1.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 17.0ms\n",
      "Speed: 5.0ms preprocess, 17.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 18.0ms\n",
      "Speed: 6.0ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 18.0ms\n",
      "Speed: 6.0ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 18.0ms\n",
      "Speed: 4.0ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 18.0ms\n",
      "Speed: 5.0ms preprocess, 18.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 384x640 1 Fall, 21.0ms\n",
      "Speed: 3.0ms preprocess, 21.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 18.0ms\n",
      "Speed: 3.0ms preprocess, 18.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 19.0ms\n",
      "Speed: 5.0ms preprocess, 19.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 24.0ms\n",
      "Speed: 2.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 26.0ms\n",
      "Speed: 1.0ms preprocess, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 22.0ms\n",
      "Speed: 6.0ms preprocess, 22.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 27.0ms\n",
      "Speed: 2.0ms preprocess, 27.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 24.0ms\n",
      "Speed: 4.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 24.0ms\n",
      "Speed: 5.0ms preprocess, 24.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 23.0ms\n",
      "Speed: 3.0ms preprocess, 23.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 24.0ms\n",
      "Speed: 3.0ms preprocess, 24.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 25.0ms\n",
      "Speed: 5.0ms preprocess, 25.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 26.0ms\n",
      "Speed: 6.0ms preprocess, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 27.0ms\n",
      "Speed: 5.0ms preprocess, 27.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 28.0ms\n",
      "Speed: 5.0ms preprocess, 28.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 25.0ms\n",
      "Speed: 5.0ms preprocess, 25.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 25.0ms\n",
      "Speed: 5.0ms preprocess, 25.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 23.0ms\n",
      "Speed: 3.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 22.0ms\n",
      "Speed: 2.0ms preprocess, 22.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 28.0ms\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 26.0ms\n",
      "Speed: 2.0ms preprocess, 26.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 23.0ms\n",
      "Speed: 4.0ms preprocess, 23.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 23.0ms\n",
      "Speed: 2.0ms preprocess, 23.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 25.0ms\n",
      "Speed: 4.0ms preprocess, 25.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 23.0ms\n",
      "Speed: 2.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 23.0ms\n",
      "Speed: 6.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 23.0ms\n",
      "Speed: 6.0ms preprocess, 23.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 22.0ms\n",
      "Speed: 2.0ms preprocess, 22.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 22.0ms\n",
      "Speed: 6.0ms preprocess, 22.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 28.0ms\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 23.0ms\n",
      "Speed: 2.0ms preprocess, 23.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 25.0ms\n",
      "Speed: 2.0ms preprocess, 25.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 26.0ms\n",
      "Speed: 2.0ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 23.0ms\n",
      "Speed: 3.0ms preprocess, 23.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 28.0ms\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 27.0ms\n",
      "Speed: 3.0ms preprocess, 27.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 32.0ms\n",
      "Speed: 3.0ms preprocess, 32.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 32.0ms\n",
      "Speed: 3.0ms preprocess, 32.0ms inference, 7.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 28.0ms\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 27.0ms\n",
      "Speed: 2.0ms preprocess, 27.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 24.0ms\n",
      "Speed: 4.0ms preprocess, 24.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 32.0ms\n",
      "Speed: 2.0ms preprocess, 32.0ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 29.0ms\n",
      "Speed: 3.0ms preprocess, 29.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 26.0ms\n",
      "Speed: 2.0ms preprocess, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 24.0ms\n",
      "Speed: 3.0ms preprocess, 24.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 26.0ms\n",
      "Speed: 2.0ms preprocess, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 26.0ms\n",
      "Speed: 1.0ms preprocess, 26.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 26.0ms\n",
      "Speed: 2.0ms preprocess, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 24.0ms\n",
      "Speed: 2.0ms preprocess, 24.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 25.0ms\n",
      "Speed: 2.0ms preprocess, 25.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 22.0ms\n",
      "Speed: 2.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 23.0ms\n",
      "Speed: 3.0ms preprocess, 23.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 24.0ms\n",
      "Speed: 2.0ms preprocess, 24.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 25.0ms\n",
      "Speed: 2.0ms preprocess, 25.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 24.0ms\n",
      "Speed: 3.0ms preprocess, 24.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 36.0ms\n",
      "Speed: 2.0ms preprocess, 36.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 24.0ms\n",
      "Speed: 2.0ms preprocess, 24.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 37.0ms\n",
      "Speed: 2.0ms preprocess, 37.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 38.0ms\n",
      "Speed: 6.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 44.0ms\n",
      "Speed: 1.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 60.0ms\n",
      "Speed: 2.0ms preprocess, 60.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 10.0ms\n",
      "Speed: 3.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 1.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 12.0ms\n",
      "Speed: 3.0ms preprocess, 12.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 33.0ms\n",
      "Speed: 3.0ms preprocess, 33.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 48.0ms\n",
      "Speed: 3.0ms preprocess, 48.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 16.0ms\n",
      "Speed: 1.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 36.0ms\n",
      "Speed: 4.0ms preprocess, 36.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 32.0ms\n",
      "Speed: 4.0ms preprocess, 32.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 39.0ms\n",
      "Speed: 3.0ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 36.0ms\n",
      "Speed: 4.0ms preprocess, 36.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 32.0ms\n",
      "Speed: 4.0ms preprocess, 32.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 26.0ms\n",
      "Speed: 4.0ms preprocess, 26.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 38.0ms\n",
      "Speed: 4.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 32.0ms\n",
      "Speed: 4.0ms preprocess, 32.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 17.0ms\n",
      "Speed: 4.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 1.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 16.0ms\n",
      "Speed: 1.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 28.0ms\n",
      "Speed: 5.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 50.0ms\n",
      "Speed: 2.0ms preprocess, 50.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 27.0ms\n",
      "Speed: 5.0ms preprocess, 27.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 38.0ms\n",
      "Speed: 3.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 28.0ms\n",
      "Speed: 3.0ms preprocess, 28.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 37.0ms\n",
      "Speed: 1.0ms preprocess, 37.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 22.0ms\n",
      "Speed: 4.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 28.0ms\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 22.0ms\n",
      "Speed: 2.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 33.0ms\n",
      "Speed: 3.0ms preprocess, 33.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 31.0ms\n",
      "Speed: 4.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 35.0ms\n",
      "Speed: 4.0ms preprocess, 35.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 32.0ms\n",
      "Speed: 3.0ms preprocess, 32.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 31.0ms\n",
      "Speed: 4.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 32.0ms\n",
      "Speed: 2.0ms preprocess, 32.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 35.0ms\n",
      "Speed: 2.0ms preprocess, 35.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 27.0ms\n",
      "Speed: 2.0ms preprocess, 27.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 26.0ms\n",
      "Speed: 5.0ms preprocess, 26.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 34.0ms\n",
      "Speed: 3.0ms preprocess, 34.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 27.0ms\n",
      "Speed: 6.0ms preprocess, 27.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 31.0ms\n",
      "Speed: 3.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 32.0ms\n",
      "Speed: 2.0ms preprocess, 32.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 32.0ms\n",
      "Speed: 4.0ms preprocess, 32.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 31.0ms\n",
      "Speed: 5.0ms preprocess, 31.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 25.0ms\n",
      "Speed: 2.0ms preprocess, 25.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 27.0ms\n",
      "Speed: 4.0ms preprocess, 27.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 27.0ms\n",
      "Speed: 2.0ms preprocess, 27.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 17.0ms\n",
      "Speed: 3.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 1.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 43.0ms\n",
      "Speed: 2.0ms preprocess, 43.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 40.0ms\n",
      "Speed: 3.0ms preprocess, 40.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 32.0ms\n",
      "Speed: 3.0ms preprocess, 32.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 38.0ms\n",
      "Speed: 2.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 36.0ms\n",
      "Speed: 2.0ms preprocess, 36.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 37.0ms\n",
      "Speed: 2.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 32.0ms\n",
      "Speed: 4.0ms preprocess, 32.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 37.0ms\n",
      "Speed: 3.0ms preprocess, 37.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 34.0ms\n",
      "Speed: 2.0ms preprocess, 34.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 32.0ms\n",
      "Speed: 9.0ms preprocess, 32.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 34.0ms\n",
      "Speed: 5.0ms preprocess, 34.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 31.0ms\n",
      "Speed: 5.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 26.0ms\n",
      "Speed: 2.0ms preprocess, 26.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 35.0ms\n",
      "Speed: 2.0ms preprocess, 35.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 27.0ms\n",
      "Speed: 4.0ms preprocess, 27.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 31.0ms\n",
      "Speed: 5.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 33.0ms\n",
      "Speed: 2.0ms preprocess, 33.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 34.0ms\n",
      "Speed: 10.0ms preprocess, 34.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 33.0ms\n",
      "Speed: 2.0ms preprocess, 33.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 35.0ms\n",
      "Speed: 8.0ms preprocess, 35.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 27.0ms\n",
      "Speed: 5.0ms preprocess, 27.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 36.0ms\n",
      "Speed: 1.0ms preprocess, 36.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 32.0ms\n",
      "Speed: 2.0ms preprocess, 32.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 32.0ms\n",
      "Speed: 5.0ms preprocess, 32.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 27.0ms\n",
      "Speed: 3.0ms preprocess, 27.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 28.0ms\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 32.0ms\n",
      "Speed: 2.0ms preprocess, 32.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 30.0ms\n",
      "Speed: 2.0ms preprocess, 30.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 47.0ms\n",
      "Speed: 5.0ms preprocess, 47.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 34.0ms\n",
      "Speed: 2.0ms preprocess, 34.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 16.0ms\n",
      "Speed: 1.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 35.0ms\n",
      "Speed: 5.0ms preprocess, 35.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 44.0ms\n",
      "Speed: 3.0ms preprocess, 44.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 33.0ms\n",
      "Speed: 3.0ms preprocess, 33.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 36.0ms\n",
      "Speed: 5.0ms preprocess, 36.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 36.0ms\n",
      "Speed: 3.0ms preprocess, 36.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 31.0ms\n",
      "Speed: 4.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 17.0ms\n",
      "Speed: 1.0ms preprocess, 17.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 16.0ms\n",
      "Speed: 2.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 18.0ms\n",
      "Speed: 1.0ms preprocess, 18.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 1.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 1.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 3.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 3.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 6.0ms\n",
      "Speed: 2.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 7.0ms\n",
      "Speed: 2.0ms preprocess, 7.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 Fall, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 7.0ms\n",
      "Speed: 1.0ms preprocess, 7.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 9.0ms\n",
      "Speed: 4.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 11.0ms\n",
      "Speed: 1.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 13.0ms\n",
      "Speed: 1.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 17.0ms\n",
      "Speed: 1.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 16.0ms\n",
      "Speed: 1.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 1.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 18.0ms\n",
      "Speed: 1.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 16.0ms\n",
      "Speed: 1.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 17.0ms\n",
      "Speed: 2.0ms preprocess, 17.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 18.0ms\n",
      "Speed: 2.0ms preprocess, 18.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 8.0ms\n",
      "Speed: 3.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 2.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 5.0ms\n",
      "Speed: 2.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 3.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 6.0ms\n",
      "Speed: 1.0ms preprocess, 6.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 5.0ms\n",
      "Speed: 1.0ms preprocess, 5.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 4.0ms\n",
      "Speed: 1.0ms preprocess, 4.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 1.0ms preprocess, 3.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 3.0ms\n",
      "Speed: 2.0ms preprocess, 3.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 8.0ms\n",
      "Speed: 1.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 9.0ms\n",
      "Speed: 3.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 9.0ms\n",
      "Speed: 2.0ms preprocess, 9.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 10.0ms\n",
      "Speed: 1.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 9.0ms\n",
      "Speed: 1.0ms preprocess, 9.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 8.0ms\n",
      "Speed: 2.0ms preprocess, 8.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 10.0ms\n",
      "Speed: 4.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 11.0ms\n",
      "Speed: 3.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 10.0ms\n",
      "Speed: 2.0ms preprocess, 10.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 11.0ms\n",
      "Speed: 2.0ms preprocess, 11.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 12.0ms\n",
      "Speed: 2.0ms preprocess, 12.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 13.0ms\n",
      "Speed: 3.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 2.0ms preprocess, 14.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 13.0ms\n",
      "Speed: 2.0ms preprocess, 13.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 14.0ms\n",
      "Speed: 1.0ms preprocess, 14.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 4.0ms preprocess, 15.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 20.0ms\n",
      "Speed: 2.0ms preprocess, 20.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 29.0ms\n",
      "Speed: 2.0ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 27.0ms\n",
      "Speed: 3.0ms preprocess, 27.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 45.0ms\n",
      "Speed: 4.0ms preprocess, 45.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 35.0ms\n",
      "Speed: 2.0ms preprocess, 35.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 31.0ms\n",
      "Speed: 4.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 30.0ms\n",
      "Speed: 5.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 28.0ms\n",
      "Speed: 3.0ms preprocess, 28.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 39.0ms\n",
      "Speed: 2.0ms preprocess, 39.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 38.0ms\n",
      "Speed: 2.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 22.0ms\n",
      "Speed: 3.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 22.0ms\n",
      "Speed: 5.0ms preprocess, 22.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 23.0ms\n",
      "Speed: 3.0ms preprocess, 23.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 26.0ms\n",
      "Speed: 5.0ms preprocess, 26.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 38.0ms\n",
      "Speed: 3.0ms preprocess, 38.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 28.0ms\n",
      "Speed: 2.0ms preprocess, 28.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 22.0ms\n",
      "Speed: 2.0ms preprocess, 22.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 25.0ms\n",
      "Speed: 4.0ms preprocess, 25.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 27.0ms\n",
      "Speed: 3.0ms preprocess, 27.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 33.0ms\n",
      "Speed: 2.0ms preprocess, 33.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 32.0ms\n",
      "Speed: 2.0ms preprocess, 32.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 26.0ms\n",
      "Speed: 3.0ms preprocess, 26.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 32.0ms\n",
      "Speed: 5.0ms preprocess, 32.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 31.0ms\n",
      "Speed: 2.0ms preprocess, 31.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 32.0ms\n",
      "Speed: 2.0ms preprocess, 32.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 25.0ms\n",
      "Speed: 3.0ms preprocess, 25.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 35.0ms\n",
      "Speed: 3.0ms preprocess, 35.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 30.0ms\n",
      "Speed: 3.0ms preprocess, 30.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 26.0ms\n",
      "Speed: 5.0ms preprocess, 26.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 32.0ms\n",
      "Speed: 3.0ms preprocess, 32.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 3.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 16.0ms\n",
      "Speed: 1.0ms preprocess, 16.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n",
      "\n",
      "0: 384x640 1 Fall, 15.0ms\n",
      "Speed: 2.0ms preprocess, 15.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "GRU 모델 실행 중 에러: input.size(-1) must be equal to input_size. Expected 27, got 26\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "from ultralytics import YOLO\n",
    "import mediapipe as mp\n",
    "\n",
    "# YOLO 모델 로드\n",
    "yolo_model = YOLO('D:\\\\project\\\\prjvenv\\\\runs\\\\detect\\\\human_fall_s30\\\\weights\\\\best.pt')\n",
    "\n",
    "# 낙상 감지 함수\n",
    "def detect_fall(landmarks, bbox_width, bbox_height, bbox_ratio, confidence):\n",
    "    processed_landmarks = process_landmarks(landmarks)\n",
    "    \n",
    "    # 랜드마크의 수를 확인\n",
    "    if processed_landmarks.shape[0] != 22:  # 11개 랜드마크 * 2 (x, y)\n",
    "        print(f\"Processed landmarks count: {processed_landmarks.shape[0]}, expected 22\")\n",
    "    \n",
    "    # 입력 데이터 생성 (confidence 포함)\n",
    "    input_data = np.concatenate([processed_landmarks, [bbox_width, bbox_height, bbox_ratio, confidence]])\n",
    "    \n",
    "    # 입력 데이터 크기 확인\n",
    "    if len(input_data) != 26:\n",
    "        print(f\"input_data length: {len(input_data)}, expected 26\")\n",
    "        return None, None\n",
    "    \n",
    "    input_tensor = torch.FloatTensor(input_data).unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = gru_model(input_tensor)\n",
    "    \n",
    "    probabilities = torch.softmax(output, dim=1).numpy()[0]\n",
    "    predicted_class = torch.argmax(output, dim=1).item()\n",
    "    \n",
    "    print(f\"Probabilities: Normal={probabilities[0]:.4f}, Danger={probabilities[1]:.4f}, Fall={probabilities[2]:.4f}\")\n",
    "    return predicted_class, probabilities\n",
    "\n",
    "# MediaPipe 초기화\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "\n",
    "LANDMARKS = [0, 11, 12, 15, 16, 23, 24, 25, 26, 27, 28]\n",
    "\n",
    "def process_landmarks(landmarks): \n",
    "    selected_landmarks = landmarks[LANDMARKS]\n",
    "    return selected_landmarks[:, :2].flatten()\n",
    "\n",
    "# GRU 모델 로드\n",
    "class GRUModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, num_layers=2, output_size=3, dropout=0.5):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "input_size = 27 # 랜드마크 x,y 좌표 + 바운딩박스 비율 + confidence\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "output_size = 3\n",
    "dropout = 0.5    \n",
    "\n",
    "gru_model = GRUModel(input_size, hidden_size, num_layers, output_size, dropout)\n",
    "gru_model.load_state_dict(torch.load('D:\\\\project\\\\prjvenv\\\\GRU\\\\best_GRU_model_2.pt', map_location=torch.device('cpu')))\n",
    "gru_model.eval()\n",
    "\n",
    "# 비디오 파일 경로 지정\n",
    "video_path = \"D:\\\\human_fall\\\\re_video\\\\training\\\\Y\\\\02735_H_A_FY_C7.mp4\"\n",
    "\n",
    "# 비디오 파일 열기\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# 비디오 속성 가져오기\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "window_w = int(width * 0.3)\n",
    "window_h = int(height * 0.3)\n",
    "\n",
    "cv2.namedWindow('Fall Detection', cv2.WINDOW_NORMAL)\n",
    "cv2.resizeWindow('Fall Detection', window_w, window_h)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# 출력 비디오 설정\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('data_video_test_outputY.mp4', fourcc, fps, (width, height))\n",
    "\n",
    "confidence_threshold = 0.3\n",
    "\n",
    "previous_bbox = None\n",
    "previous_label = None\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # YOLO 모델 실행\n",
    "    results = yolo_model(frame)\n",
    "    \n",
    "    # YOLO 결과 처리\n",
    "    for result in results:\n",
    "        boxes = result.boxes.xyxy.cpu().numpy().astype(int)\n",
    "        confidences = result.boxes.conf.cpu().numpy()\n",
    "        class_ids = result.boxes.cls.cpu().numpy()\n",
    "        \n",
    "        if len(boxes) > 0:\n",
    "            # YOLO가 객체를 감지한 경우 (바운딩 박스만 사용)\n",
    "            box_indices_to_process = [i for i in range(len(boxes)) if confidences[i] > confidence_threshold]\n",
    "            for i in box_indices_to_process:\n",
    "                box = boxes[i]  # 각 객체의 바운딩 박스 처리\n",
    "                confidence = confidences[i]\n",
    "                class_id = class_ids[i]\n",
    "                \n",
    "                x1, y1, x2, y2 = box\n",
    "                bbox_width = x2 - x1\n",
    "                bbox_height = y2 - y1\n",
    "                bbox_ratio = bbox_width / bbox_height\n",
    "                \n",
    "                # MediaPipe 처리\n",
    "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "                results_pose = pose.process(rgb_frame)\n",
    "                \n",
    "                if results_pose.pose_landmarks:\n",
    "                    landmarks = np.array([[lm.x * frame.shape[1], lm.y * frame.shape[0]] for lm in results_pose.pose_landmarks.landmark])\n",
    "                    \n",
    "                    try:\n",
    "                        # GRU 모델을 통해 클래스 예측 (confidence를 포함하여 호출)\n",
    "                        label, probs = detect_fall(landmarks, bbox_width, bbox_height, bbox_ratio ,confidence) \n",
    "                        previous_bbox = (x1,y1,x2,y2)\n",
    "                        previous_label = label\n",
    "\n",
    "                        # 바운딩 박스 색상 결정 (확률 기반으로 결정)\n",
    "                        if probs[2] > 0.5:  # Fall 클래스 확률이 50% 이상일 때 빨간색으로 표시 (Fall은 빨간색으로 설정됨)\n",
    "                            color = (0 ,0 ,255)   # Fall: Red\n",
    "                        elif probs[1] > 0.5:   # Danger 클래스 확률이 50% 이상일 때 노란색으로 표시\n",
    "                            color = (0 ,255 ,255)   # Danger: Yellow\n",
    "                        else:\n",
    "                            color = (0 ,255 ,0)   # Normal: Green\n",
    "\n",
    "                        # 바운딩 박스 그리기 및 레이블 표시하기\n",
    "                        cv2.rectangle(frame,(x1,y1),(x2,y2),color ,2) \n",
    "                        cv2.putText(frame,f'Class: {label}', (x1,y1 -10), cv2.FONT_HERSHEY_SIMPLEX ,0.7,color ,2)\n",
    "\n",
    "                    except Exception as e:\n",
    "                        print(f\"GRU 모델 실행 중 에러: {e}\")\n",
    "                        label, probs = previous_label if previous_label is not None else (None,None)\n",
    "\n",
    "                else:\n",
    "                    # MediaPipe가 랜드마크를 감지하지 못한 경우 YOLO 결과 표시 (바운딩 박스만 그리기)\n",
    "                    color_map_default = {0: (255 ,0 ,0), 1: (255 ,255 ,0)}  \n",
    "                    color_default= color_map_default[class_id] if class_id in color_map_default else (255 ,255 ,255) \n",
    "                    cv2.rectangle(frame,(x1,y1),(x2,y2),color_default ,2)  \n",
    "                    cv2.putText(frame,f\"YOLO Class ID: {class_id}\",(x1,y1 -30),cv2.FONT_HERSHEY_SIMPLEX ,0.7,color_default ,2)\n",
    "\n",
    "    # 프레임 저장 및 출력\n",
    "    out.write(frame)\n",
    "    cv2.imshow('Fall Detection', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

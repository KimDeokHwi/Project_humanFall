{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[5544]: Class CaptureDelegate is implemented in both /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/cv2/cv2.abi3.so (0x15c99a6b8) and /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/mediapipe/.dylibs/libopencv_videoio.3.4.16.dylib (0x127e30860). One of the two will be used. Which one is undefined.\n",
      "objc[5544]: Class CVWindow is implemented in both /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/cv2/cv2.abi3.so (0x15c99a708) and /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x116a00a68). One of the two will be used. Which one is undefined.\n",
      "objc[5544]: Class CVView is implemented in both /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/cv2/cv2.abi3.so (0x15c99a730) and /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x116a00a90). One of the two will be used. Which one is undefined.\n",
      "objc[5544]: Class CVSlider is implemented in both /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/cv2/cv2.abi3.so (0x15c99a758) and /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x116a00ab8). One of the two will be used. Which one is undefined.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS\n"
     ]
    }
   ],
   "source": [
    "# MPS 사용 가능 여부 확인\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "2024-11-23 18:23:22.433 Python[5544:146901] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n",
      "2024-11-23 18:23:24.682 Python[5544:146901] +[IMKClient subclass]: chose IMKClient_Legacy\n",
      "2024-11-23 18:23:24.682 Python[5544:146901] +[IMKInputSession subclass]: chose IMKInputSession_Legacy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 0\n",
      "Predicted Class: 2\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 2\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 0\n",
      "Predicted Class: 1\n",
      "Predicted Class: 0\n",
      "Predicted Class: 2\n",
      "Predicted Class: 0\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 2\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 2\n",
      "Predicted Class: 2\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 2\n",
      "Predicted Class: 0\n",
      "Predicted Class: 1\n",
      "Predicted Class: 0\n",
      "Predicted Class: 2\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 2\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 2\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 0\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 1\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 0\n",
      "Predicted Class: 1\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 1\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 1\n",
      "Predicted Class: 0\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 0\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 0\n",
      "Predicted Class: 1\n",
      "Predicted Class: 1\n",
      "Predicted Class: 0\n",
      "Predicted Class: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# MediaPipe 초기화\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 랜드마크 인덱스 정의 (예: 코, 왼쪽 어깨, 오른쪽 어깨 등)\n",
    "LANDMARKS = [0, 11, 12, 15, 16, 23, 24, 25, 26, 27, 28]  # 총 11개 랜드마크\n",
    "\n",
    "# GRU 모델 정의\n",
    "class GRUModel(torch.nn.Module):\n",
    "    def __init__(self, input_size=27):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size = 64\n",
    "        self.num_layers = num_layers = 2\n",
    "        self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True,\n",
    "                          dropout=0.5)\n",
    "        self.fc = nn.Linear(hidden_size, 3)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# GRU 모델 로드\n",
    "input_size = 27\n",
    "gru_model = GRUModel(input_size=input_size)  \n",
    "gru_model.load_state_dict(torch.load('/Users/kimdeok-hwi/deeplearning/project/Project_humanFall/GRU/best_GRU_model_2.pt', map_location=torch.device('cpu')))\n",
    "gru_model.eval()\n",
    "\n",
    "# 클래스 이름 정의\n",
    "class_names = {0: 'Normal', 1: 'Fall', 2: 'Danger'}\n",
    "\n",
    "# Threshold 값 정의\n",
    "threshold_normal = 6.5   # 일반 상태로 간주되는 속도 임계값\n",
    "threshold_danger = 10.5   # 위험 상태로 간주되는 속도 임계값\n",
    "\n",
    "def calculate_head_upper_body_speed(keypoints, prev_keypoints):\n",
    "    h = np.array([keypoints[0, 0], keypoints[0, 1]])   # 머리 좌표\n",
    "    l = np.array([keypoints[11, 0], keypoints[11, 1]])  # 왼쪽 어깨 좌표\n",
    "    r = np.array([keypoints[12, 0], keypoints[12, 1]])  # 오른쪽 어깨 좌표\n",
    "\n",
    "    # 이전 프레임의 좌표가 없는 경우 속도는 0으로 설정\n",
    "    if prev_keypoints is None:\n",
    "        return 0.0\n",
    "\n",
    "    prev_h = np.array([prev_keypoints[0, 0], prev_keypoints[0, 1]])\n",
    "    prev_l = np.array([prev_keypoints[11, 0], prev_keypoints[11, 1]])\n",
    "    prev_r = np.array([prev_keypoints[12, 0], prev_keypoints[12, 1]])\n",
    "\n",
    "    # 현재 프레임과 이전 프레임의 상체 중심 계산\n",
    "    center_new = (h + l + r) / 3\n",
    "    center_prev = (prev_h + prev_l + prev_r) / 3\n",
    "\n",
    "    # 유클리드 거리 계산 (속도)\n",
    "    speed = distance.euclidean(center_new, center_prev)\n",
    "    return speed\n",
    "\n",
    "def process_landmarks(landmarks): \n",
    "    selected_landmarks = landmarks[LANDMARKS]   # 지정된 랜드마크 선택 \n",
    "    return selected_landmarks[:, :2].flatten()   # (x,y) 좌표 반환\n",
    "\n",
    "def calculate_and_draw_bbox(frame, landmarks):\n",
    "    x_coordinates = landmarks[:, 0]\n",
    "    y_coordinates = landmarks[:, 1]\n",
    "    \n",
    "    x1 = max(0, int(np.min(x_coordinates)))\n",
    "    y1 = max(0, int(np.min(y_coordinates)))\n",
    "    x2 = min(frame.shape[1], int(np.max(x_coordinates)))\n",
    "    y2 = min(frame.shape[0], int(np.max(y_coordinates)))\n",
    "    \n",
    "    bbox_width = x2 - x1\n",
    "    bbox_height = y2 - y1\n",
    "    \n",
    "    # 높이가 0일 경우 비율을 무한대로 설정\n",
    "    bbox_ratio = bbox_width / bbox_height if bbox_height != 0 else float('inf')\n",
    "    \n",
    "    # 바운딩 박스를 조금 더 넓게 조정 (각 방향으로 패딩 추가)\n",
    "    padding = 50\n",
    "    x1 = max(0, x1 - padding)\n",
    "    y1 = max(0, y1 - padding)\n",
    "    x2 = min(frame.shape[1], x2 + padding)\n",
    "    y2 = min(frame.shape[0], y2 + padding)\n",
    "\n",
    "    return (x1, y1), (x2, y2), bbox_width, bbox_height\n",
    "\n",
    "# 낙상 감지 함수\n",
    "def detect_fall(landmarks, prev_landmarks):\n",
    "    speed = calculate_head_upper_body_speed(landmarks, prev_landmarks)\n",
    "    \n",
    "    processed_landmarks = process_landmarks(landmarks)\n",
    "\n",
    "    # 바운딩 박스 계산 및 그리기 \n",
    "    top_left_bbox, bottom_right_bbox, bbox_width, bbox_height = calculate_and_draw_bbox(frame, landmarks)\n",
    "    \n",
    "    # 바운딩 박스 비율 계산\n",
    "    bbox_ratio = bbox_width / bbox_height if bbox_height != 0 else float('inf')\n",
    "\n",
    "    # 속도 기반 클래스 결정\n",
    "    if speed < threshold_normal:\n",
    "        bbox_class = 0   # Normal \n",
    "    elif speed < threshold_danger:\n",
    "        bbox_class = 2   # Danger \n",
    "    else:\n",
    "        bbox_class = 1   # Fall \n",
    "    \n",
    "    # 바운딩 박스 비율에 따른 클래스 조정\n",
    "    if bbox_class == 0 and bbox_ratio < 0.5:\n",
    "        bbox_class = 0   # Normal에서 Normal로 조정\n",
    "    elif bbox_class == 0 and 0.5 <= bbox_ratio <= 0.7: \n",
    "        bbox_class = 2   # Normal에서 Danger로 조정\n",
    "    elif bbox_class == 0 and bbox_ratio > 1: \n",
    "        bbox_class = 1   # Normal에서 Fall로 조정\n",
    "        \n",
    "    elif bbox_class == 2 and bbox_ratio < 0.5: \n",
    "        bbox_class = 0\n",
    "    elif bbox_class == 2 and 0.5 <= bbox_ratio <= 0.7: \n",
    "        bbox_class = 2\n",
    "    elif bbox_class == 2 and bbox_ratio > 1: \n",
    "        bbox_class = 1\n",
    "        \n",
    "    elif bbox_class == 1 and bbox_ratio < 0.5: \n",
    "        bbox_class = 0\n",
    "    elif bbox_class == 1 and 0.5 <= bbox_ratio <= 0.7: \n",
    "        bbox_class = 2\n",
    "    elif bbox_class == 1 and bbox_ratio > 1: \n",
    "        bbox_class = 1\n",
    "\n",
    "    return bbox_class\n",
    "\n",
    "# 웹캠 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "prev_landmarks = None\n",
    "\n",
    "# 비디오 속성 가져오기\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = 24\n",
    "\n",
    "# 출력 비디오 설정\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out_path = f'try_fall_detection_by_webcam.mp4' \n",
    "actual_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "out = cv2.VideoWriter(out_path, fourcc, fps, (width, height))\n",
    "\n",
    "prev_landmarks = None\n",
    "\n",
    "# 프레임 처리 루프 \n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results_pose = pose.process(rgb_frame)\n",
    "\n",
    "    if results_pose.pose_landmarks:\n",
    "        landmarks = np.array([[lm.x * frame.shape[1], lm.y * frame.shape[0], lm.z] for lm in results_pose.pose_landmarks.landmark])\n",
    "       \n",
    "        if prev_landmarks is not None: \n",
    "            label = detect_fall(landmarks, prev_landmarks)  \n",
    "            print(f\"Predicted Class: {label}\")  \n",
    "        else: \n",
    "            label = None \n",
    "\n",
    "        prev_landmarks = landmarks \n",
    "\n",
    "        # 바운딩 박스와 라벨 그리기 \n",
    "        top_left_bbox, bottom_right_bbox, _, _ = calculate_and_draw_bbox(frame, landmarks)  \n",
    "        color = (0, 255, 0) if label == 0 else ((0, 255, 255) if label == 2 else (0, 0, 255)) \n",
    "        cv2.rectangle(frame, top_left_bbox, bottom_right_bbox, color, 2)\n",
    "        class_name = class_names[label] if label is not None else 'Unknown'\n",
    "        cv2.putText(frame, f'{class_name}', (top_left_bbox[0], top_left_bbox[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 3)\n",
    "\n",
    "        # 랜드마크 표시 \n",
    "        mp_drawing.draw_landmarks(frame, results_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "    # 프레임 저장\n",
    "    out.write(frame)\n",
    "\n",
    "    # 프레임 출력 \n",
    "    cv2.imshow('Fall Detection', frame) \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "         break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

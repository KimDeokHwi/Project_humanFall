{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "objc[1528]: Class CaptureDelegate is implemented in both /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/cv2/cv2.abi3.so (0x15219a6b8) and /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/mediapipe/.dylibs/libopencv_videoio.3.4.16.dylib (0x145f38860). One of the two will be used. Which one is undefined.\n",
      "objc[1528]: Class CVWindow is implemented in both /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/cv2/cv2.abi3.so (0x15219a708) and /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x124fe8a68). One of the two will be used. Which one is undefined.\n",
      "objc[1528]: Class CVView is implemented in both /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/cv2/cv2.abi3.so (0x15219a730) and /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x124fe8a90). One of the two will be used. Which one is undefined.\n",
      "objc[1528]: Class CVSlider is implemented in both /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/cv2/cv2.abi3.so (0x15219a758) and /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/mediapipe/.dylibs/libopencv_highgui.3.4.16.dylib (0x124fe8ab8). One of the two will be used. Which one is undefined.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS\n"
     ]
    }
   ],
   "source": [
    "# MPS 사용 가능 여부 확인\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    print(\"MPS\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CPU\")"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 15,
>>>>>>> 99e932a8d329b00a0f9a9a6a3610839502574b74
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n",
      "Class :1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MediaPipe 초기화\n",
    "mp_pose = mp.solutions.pose\n",
    "pose = mp_pose.Pose(static_image_mode=False, min_detection_confidence=0.5)\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "\n",
    "# 랜드마크 인덱스 정의 (예: 코, 왼쪽 어깨, 오른쪽 어깨 등)\n",
    "LANDMARKS = [0, 11, 12, 15, 16, 23, 24, 25, 26, 27, 28]  # 총 11개 랜드마크\n",
    "\n",
    "# Threshold 값 정의\n",
    "threshold_normal = 8.5   # 일반 상태로 간주되는 속도 임계값\n",
    "threshold_danger = 15.5   # 위험 상태로 간주되는 속도 임계값\n",
    "\n",
    "def calculate_head_upper_body_speed(keypoints, prev_keypoints):\n",
    "    h = np.array([keypoints[0, 0], keypoints[0, 1]])   # 머리 좌표\n",
    "    l = np.array([keypoints[11, 0], keypoints[11, 1]])  # 왼쪽 어깨 좌표\n",
    "    r = np.array([keypoints[12, 0], keypoints[12, 1]])  # 오른쪽 어깨 좌표\n",
    "\n",
    "    # 이전 프레임의 좌표가 없는 경우 속도는 0으로 설정\n",
    "    if prev_keypoints is None:\n",
    "        return 0.0\n",
    "\n",
    "    prev_h = np.array([prev_keypoints[0, 0], prev_keypoints[0, 1]])\n",
    "    prev_l = np.array([prev_keypoints[11, 0], prev_keypoints[11, 1]])\n",
    "    prev_r = np.array([prev_keypoints[12, 0], prev_keypoints[12, 1]])\n",
    "\n",
    "    # 현재 프레임과 이전 프레임의 상체 중심 계산\n",
    "    center_new = (h + l + r) / 3\n",
    "    center_prev = (prev_h + prev_l + prev_r) / 3\n",
    "\n",
    "    # 유클리드 거리 계산 (속도)\n",
    "    speed = distance.euclidean(center_new, center_prev)\n",
    "    return speed\n",
    "\n",
    "# GRU 모델 정의\n",
    "class GRUModel(torch.nn.Module):\n",
    "    def __init__(self, input_size=27):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size = 64\n",
    "        self.num_layers = num_layers = 2\n",
    "        self.gru = nn.GRU(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first=True,\n",
    "                          dropout=0.5)\n",
    "        self.fc = nn.Linear(hidden_size, 3)  # output_size를 직접 지정합니다.\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        out, _ = self.gru(x, h0)\n",
    "        out = self.dropout(out[:, -1, :])\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "# GRU 모델 로드\n",
    "input_size = 27\n",
    "gru_model = GRUModel(input_size=input_size)  \n",
    "gru_model.load_state_dict(torch.load('D:\\\\project\\\\prjvenv\\\\GRU\\\\best_GRU_model_2.pt', map_location=torch.device('cpu')))\n",
    "gru_model.eval()\n",
    "\n",
    "# GPU 사용 가능 시 GPU로 모델 이동\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gru_model = gru_model.to(device)\n",
    "\n",
    "# 클래스 이름 정의\n",
    "class_names = {0: 'Normal', 1: 'Fall', 2: 'Danger'}\n",
    "\n",
    "def process_landmarks(landmarks, bbox, speed):\n",
    "    selected_landmarks = landmarks[LANDMARKS]   # 지정된 랜드마크 선택\n",
    "    landmark_features = selected_landmarks[:, :2].flatten()  # (x,y) 좌표\n",
    "    bbox_features = np.array(bbox).flatten()  # 바운딩 박스 좌표\n",
    "    speed_feature = np.array([speed])  # 속도\n",
    "    \n",
    "    # 모든 특성을 결합\n",
    "    features = np.concatenate([landmark_features, bbox_features, speed_feature])\n",
    "    \n",
    "    return features  # 총 27개의 특성 (22 + 4 + 1)\n",
    "\n",
    "def calculate_and_draw_bbox(frame, landmarks):\n",
    "    x_coordinates = landmarks[:, 0]\n",
    "    y_coordinates = landmarks[:, 1]\n",
    "    \n",
    "    x1 = max(0, int(np.min(x_coordinates)))\n",
    "    y1 = max(0, int(np.min(y_coordinates)))\n",
    "    x2 = min(frame.shape[1], int(np.max(x_coordinates)))\n",
    "    y2 = min(frame.shape[0], int(np.max(y_coordinates)))\n",
    "    \n",
    "    bbox_width = x2 - x1\n",
    "    bbox_height = y2 - y1\n",
    "    \n",
    "    # 바운딩 박스를 조금 더 넓게 조정 (각 방향으로 패딩 추가)\n",
    "    padding = 50\n",
    "    x1 = max(0, x1 - padding)\n",
    "    y1 = max(0, y1 - padding)\n",
    "    x2 = min(frame.shape[1], x2 + padding)\n",
    "    y2 = min(frame.shape[0], y2 + padding)\n",
    "\n",
    "    return (x1, y1, x2, y2), bbox_width, bbox_height\n",
    "\n",
    "# 낙상 감지 함수\n",
<<<<<<< HEAD
    "def detect_fall(frame, landmarks, prev_landmarks, fall_frame_counter):\n",
    "    global determine_fall, gru_model\n",
    "    \n",
    "    if determine_fall:\n",
    "        return 1, fall_frame_counter\n",
    "    \n",
    "    speed = calculate_head_upper_body_speed(landmarks, prev_landmarks)\n",
    "    bbox, bbox_width, bbox_height = calculate_and_draw_bbox(frame, landmarks)\n",
    "    bbox_ratio = bbox_width / bbox_height if bbox_height != 0 else float('inf')\n",
    "    \n",
    "    processed_landmarks = process_landmarks(landmarks, bbox, speed)\n",
    "    \n",
    "    # GRU 모델 입력을 위한 데이터 준비\n",
    "    input_data = torch.FloatTensor(processed_landmarks).unsqueeze(0).unsqueeze(0).to(device)\n",
    "    \n",
    "    # GRU 모델을 통한 예측\n",
    "    with torch.no_grad():\n",
    "        output = gru_model(input_data)\n",
    "        _, predicted = torch.max(output.data, 1)\n",
    "        bbox_class = predicted.item()\n",
    "    \n",
    "    # 후처리: 속도와 bbox_ratio를 기반으로 예측 결과 보정\n",
    "    if speed < threshold_normal and bbox_ratio < 0.5:\n",
    "        bbox_class = 0  # Normal\n",
    "    elif speed >= threshold_danger or bbox_ratio > 1:\n",
    "        bbox_class = 1  # Fall\n",
=======
    "def detect_fall(landmarks, prev_landmarks, fall_frame_counter):\n",
    "    global determine_fall\n",
    "    if determine_fall : \n",
    "        return 1, fall_frame_counter\n",
    "    \n",
    "    speed = calculate_head_upper_body_speed(landmarks, prev_landmarks)\n",
    "    top_left_bbox, bottom_right_bbox, bbox_width, bbox_height = calculate_and_draw_bbox(frame, landmarks)\n",
    "    bbox_ratio = bbox_width / bbox_height if bbox_height != 0 else float('inf')\n",
    "\n",
    "    # 속도 기반 클래스 결정\n",
    "    if speed < threshold_normal:\n",
    "        bbox_class = 0   # Normal \n",
    "    elif speed < threshold_danger:\n",
    "        bbox_class = 2   # Danger \n",
>>>>>>> 99e932a8d329b00a0f9a9a6a3610839502574b74
    "    else:\n",
    "        bbox_class = 2  # Danger\n",
    "            \n",
    "    print(f\"Speed: {speed}, bbox_ratio: {bbox_ratio}\")\n",
    "    print(f\"Final predicted class after post-processing: {bbox_class}\")\n",
    "    \n",
    "    # Fall_counter 업데이트\n",
    "    if bbox_class == 1:\n",
    "        fall_frame_counter += 1\n",
    "        if fall_frame_counter >= 10:\n",
    "            determine_fall = True\n",
    "    else:\n",
    "        fall_frame_counter = 0\n",
    "\n",
    "    return bbox_class, fall_frame_counter\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# 비디오 속성 가져오기 \n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = 30\n",
    "cap.set(cv2.CAP_PROP_FPS, fps)\n",
    "\n",
    "# 출력 비디오 설정 \n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out_path = 'GRU_model_Y_8.mp4'\n",
    "out = cv2.VideoWriter(out_path, fourcc, fps, (width, height))\n",
    "\n",
    "# 프레임 처리 루프 \n",
    "fall_frame_counter = 0\n",
    "determine_fall = False\n",
    "prev_landmarks = None\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results_pose = pose.process(rgb_frame)\n",
    "\n",
    "    if results_pose.pose_landmarks:\n",
    "        landmarks = np.array([[lm.x * width, lm.y * height, lm.z] for lm in results_pose.pose_landmarks.landmark])\n",
    "       \n",
    "        label, fall_frame_counter = detect_fall(frame, landmarks, prev_landmarks, fall_frame_counter)  \n",
    "        print(f\"Predicted Class: {label}\")  \n",
    "\n",
    "        # 바운딩 박스와 라벨 그리기 \n",
<<<<<<< HEAD
    "        bbox, _, _ = calculate_and_draw_bbox(frame, landmarks)\n",
=======
    "        top_left_bbox, bottom_right_bbox, _, _ = calculate_and_draw_bbox(frame, landmarks)  \n",
>>>>>>> 99e932a8d329b00a0f9a9a6a3610839502574b74
    "        color = (0, 255, 0) if label == 0 else ((0, 255, 255) if label == 2 else (0, 0, 255)) \n",
    "        cv2.rectangle(frame, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color, 2)\n",
    "        class_name = class_names[label] if label is not None else 'Unknown'\n",
    "        cv2.putText(frame, f'GRU: {class_name}', (bbox[0], bbox[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)\n",
    "\n",
    "        if determine_fall: \n",
    "            cv2.putText(frame, 'FALL', (10, 30), cv2.FONT_HERSHEY_DUPLEX, 1, (0, 0, 255), 3)\n",
    "        # 랜드마크 표시 \n",
    "        mp_drawing.draw_landmarks(frame, results_pose.pose_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "\n",
    "        prev_landmarks = landmarks\n",
    "\n",
    "    # 프레임 저장 및 출력 \n",
    "    resized_frame = cv2.resize(frame, (1920, 1080))  \n",
    "    out.write(frame) \n",
    "    cv2.imshow('Fall Detection', resized_frame) \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "         break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
